{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "서울대_모델반영의 사본",
      "provenance": [],
      "collapsed_sections": [
        "1l25XQ_snXiA"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8cCwJk0_DesR"
      },
      "source": [
        "참고: https://zzsza.github.io/data/2018/08/30/google-colab/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG1m10b9aekq",
        "colab_type": "text"
      },
      "source": [
        "# 개요\n",
        "\n",
        "서울대 RNN2 학습/검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0-QrbvLGzlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "de7cab0c-da38-442c-f8d7-d6954797fd6b"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import pathlib\n",
        "!pip3 install gcsfs dask\n",
        "import gcsfs\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.activations as act\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.regularizers as reg\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 40kB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.17.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (42.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n",
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/10/891a143325fb237bd4f990efcd13fac257af8dcd6525f804981eb5f6f632/gcsfs-0.5.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6dfGM_E5hHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2596bacc-5942-4c8e-cf0e-96857b608cc8"
      },
      "source": [
        "# 유닉스 정보 조회\n",
        "!cat /etc/issue.net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ubuntu 18.04.3 LTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Se02GE2E5SG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "91865577-bc1b-4c70-f5d8-84ca703c2469"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec  6 00:46:28 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWb4HkVm0MM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f5962f9-403a-44fe-d107-c239fc4542fc"
      },
      "source": [
        "!grep -c processor /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOaebyOZIN2Z",
        "colab_type": "text"
      },
      "source": [
        "## 구글 드라이브 마운트\n",
        "\n",
        "구글 계정에 인증을 물어온다. 두번 물어 올 수 있음.\n",
        "\n",
        "내 구글 드라이브의 폴더를 colab에 마운트 할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHz9HUTE52WC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3325b387-d1aa-47e8-f5de-31501d9b9790"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rWtg6sK5B7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ddaea372-51b7-43a8-df7e-2e3390e6e60c"
      },
      "source": [
        "!gcloud auth list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Credentialed Accounts\n",
            "ACTIVE  ACCOUNT\n",
            "*       jangmin.o@wemakeprice.com\n",
            "\n",
            "To set the active account, run:\n",
            "    $ gcloud config set account `ACCOUNT`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KzjjL5jHErt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = pathlib.Path('gdrive/My Drive/snu_project')\n",
        "BATCH_SIZE=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWL7XbUA4YA-",
        "colab_type": "text"
      },
      "source": [
        "빅쿼리에서 데이터 로딩 (일회성)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtyKrT61Fg2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86f3a973-b020-4f13-ce28-83ff3fb013f8"
      },
      "source": [
        "%env GOOGLE_CLOUD_PROJECT=eighth-edge-810"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: GOOGLE_CLOUD_PROJECT=eighth-edge-810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ_Tgd0AFZi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery prod_df\n",
        "SELECT prod_no, prod_nm, prod2i, mcate_cd, mcate2i FROM `eighth-edge-810.wmind_datamart.snu_ordered_prod_info_20191126`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0su2ST_G0al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod_df.to_pickle(str(base_path.joinpath('ordered_prod_info.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVyx7p3PJWMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery train_df\n",
        "SELECT mid, train_data as data FROM `eighth-edge-810.wmind_datamart.snu_instances_20191126`, unnest(train) as train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXmPLjPFToo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['data'] = train_df.data.apply(lambda x: json.loads(x))\n",
        "train_df = shuffle(train_df)\n",
        "train_df.to_pickle(str(base_path.joinpath('train.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKwzbP_QJlWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery valid_df\n",
        "SELECT mid, valid_data as data FROM `eighth-edge-810.wmind_datamart.snu_instances_20191126`, unnest(valid) as valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3fnBrN0Jrck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_df['data'] = valid_df.data.apply(lambda x: json.loads(x))\n",
        "valid_df = shuffle(valid_df)\n",
        "valid_df.to_pickle(str(base_path.joinpath('validation.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dFJqK2cW1kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery test_df\n",
        "SELECT mid, test_data as data FROM `eighth-edge-810.wmind_datamart.snu_instances_20191126`, unnest(test) as test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHDAG3AuW1AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['data'] = test_df.data.apply(lambda x: json.loads(x))\n",
        "test_df = shuffle(test_df)\n",
        "test_df.to_pickle(str(base_path.joinpath('test.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oi19Qwo5G0-",
        "colab_type": "text"
      },
      "source": [
        "TF에 넣을 데이터만 추림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYK37boS5KqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_pickle(str(base_path.joinpath('train.pkl.gz')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ynKjNFiZA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_df.data.apply(lambda x: np.concatenate((np.array(x['prod2is'],dtype=np.int32).reshape((-1, 1)), np.array(x['mcate2is'],dtype=np.int32).reshape((-1, 1))), axis=1 ))\n",
        "y = train_df.data.apply(lambda x: np.int32(x['label']))\n",
        "train_data_df = pd.concat([train_df.mid, x.rename('x'), y.rename('label')], axis=1)\n",
        "train_data_df.to_pickle(str(base_path.joinpath('train_data_df.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hd3lpzRwnAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c2e5d931-3b55-4e9a-f1c6-4183b5faf046"
      },
      "source": [
        "train_data_df.x.iloc[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[943059,    374],\n",
              "       [943821,     45],\n",
              "       [947422,    192],\n",
              "       [950139,    368],\n",
              "       [945437,    372],\n",
              "       [937926,     27],\n",
              "       [807501,    199],\n",
              "       [953043,     68]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq6RTgYe9zc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_df = pd.read_pickle(str(base_path.joinpath('validation.pkl.gz')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYLMPTbV7gCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = valid_df.data.apply(lambda x: np.concatenate((np.array(x['prod2is'],dtype=np.int32).reshape((-1, 1)), np.array(x['mcate2is'],dtype=np.int32).reshape((-1, 1))), axis=1 ))\n",
        "y = valid_df.data.apply(lambda x: np.int32(x['label']))\n",
        "valid_data_df = pd.concat([valid_df.mid, x.rename('x'), y.rename('label')], axis=1)\n",
        "valid_data_df.to_pickle(str(base_path.joinpath('valid_data_df.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Ui5PTQXpJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_pickle(str(base_path.joinpath('test.pkl.gz')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_tVeMWXohr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = test_df.data.apply(lambda x: np.concatenate((np.array(x['prod2is'],dtype=np.int32).reshape((-1, 1)), np.array(x['mcate2is'],dtype=np.int32).reshape((-1, 1))), axis=1 ))\n",
        "y = test_df.data.apply(lambda x: np.int32(x['label']))\n",
        "test_data_df = pd.concat([test_df.mid, x.rename('x'), y.rename('label')], axis=1)\n",
        "test_data_df.to_pickle(str(base_path.joinpath('test_data_df.pkl.gz')), 'gzip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFAKAYNVa9TN",
        "colab_type": "text"
      },
      "source": [
        "fasttext를 수행할 타이틀 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q0-TkeNIjLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod_df.prod_nm.to_csv(str(base_path.joinpath('prod_nms.csv')), index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLw1EaygJZP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "d3f02526-513d-46a3-ed72-05a89f82df67"
      },
      "source": [
        "!gsutil -m cp 'gdrive/My Drive/snu_project/*' gs://recom-test/snu_project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://gdrive/My Drive/snu_project/ordered_prod_info.pkl.gz [Content-Type=application/octet-stream]...\n",
            "Copying file://gdrive/My Drive/snu_project/validation.pkl.gz [Content-Type=application/octet-stream]...\n",
            "Copying file://gdrive/My Drive/snu_project/test.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \r/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \rCopying file://gdrive/My Drive/snu_project/test_data_df.pkl.gz [Content-Type=application/octet-stream]...\n",
            "Copying file://gdrive/My Drive/snu_project/train.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \r/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \r/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \rCopying file://gdrive/My Drive/snu_project/train_data_df.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \rCopying file://gdrive/My Drive/snu_project/prod_nms.csv [Content-Type=text/csv]...\n",
            "/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \rCopying file://gdrive/My Drive/snu_project/valid_data_df.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [0/8 files][    0.0 B/617.6 MiB]   0% Done                                    \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/ [8/8 files][617.6 MiB/617.6 MiB] 100% Done                                    \n",
            "Operation completed over 8 objects/617.6 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7laOJkv7_Gln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0eae56ed-57b0-401e-dd6e-13a6c897846a"
      },
      "source": [
        "!gsutil -m cp gs://recom-test/snu_project/prod_emb_mat.npy 'gdrive/My Drive/snu_project/fasttext'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://recom-test/snu_project/prod_emb_mat.npy...\n",
            "| [1/1 files][472.0 MiB/472.0 MiB] 100% Done  43.6 MiB/s ETA 00:00:00           \n",
            "Operation completed over 1 objects/472.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pmpHSh9DwHq",
        "colab_type": "text"
      },
      "source": [
        "이후 여기부터 시작\n",
        "\n",
        "- D: embedding dimension\n",
        "- P: # or products\n",
        "- M: # or mcate\n",
        "- B: BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2inClm5bJQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e492e498-6c65-43bc-e969-0481e5dd3a13"
      },
      "source": [
        "%%time\n",
        "train_data_df = pd.read_pickle(str(base_path.joinpath('train_data_df.pkl.gz')))\n",
        "valid_data_df = pd.read_pickle(str(base_path.joinpath('valid_data_df.pkl.gz')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.1 s, sys: 1.16 s, total: 12.3 s\n",
            "Wall time: 13.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3pRe_MDGlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod_df = pd.read_pickle(str(base_path.joinpath('ordered_prod_info.pkl.gz')))\n",
        "prod_df = prod_df.sort_values(by=['prod2i']).set_index('prod2i')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49I6ahaNDNXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "P = prod_df.shape[0]\n",
        "M = prod_df.mcate2i.value_counts().shape[0]\n",
        "D = 128\n",
        "B = BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gmfX5_U-geE",
        "colab_type": "text"
      },
      "source": [
        "임베딩 행렬 로딩: shape==[P, D]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QACvmTPK-0bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_prod_embedding = np.load(str(base_path.joinpath(\"fasttext\").joinpath(\"prod_emb_mat.npy\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr0rLIleEXib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "0e6c5fd5-9960-4fc8-b9bb-336f4b4d2f74"
      },
      "source": [
        "np_prod_embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.09749427,  0.0040447 , -0.15179805, ...,  0.01083633,\n",
              "        -0.07715385, -0.06197934],\n",
              "       [ 0.07218083, -0.01890226, -0.19205369, ...,  0.01039626,\n",
              "        -0.05714676, -0.04734085],\n",
              "       ...,\n",
              "       [-0.0528723 , -0.00954199, -0.07857933, ..., -0.07444088,\n",
              "        -0.15658966,  0.00219295],\n",
              "       [-0.00745197, -0.06100256,  0.04682942, ...,  0.02340629,\n",
              "        -0.11738155, -0.04557302],\n",
              "       [-0.12385555, -0.03802903,  0.0650975 , ..., -0.06814113,\n",
              "        -0.13313623,  0.01738781]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvt1s_aG_gLz",
        "colab_type": "text"
      },
      "source": [
        "데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGpa9SZ1pI8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAz8R7MPoJIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen(df):\n",
        "  for idx, row in df.iterrows():\n",
        "    yield(row.mid, row.x, row.x.shape[0], row.label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gnt12_Do7b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = tf.data.Dataset.from_generator(partial(gen, train_data_df), (tf.int64, tf.int32, tf.int32, tf.int32), (tf.TensorShape([]), tf.TensorShape([None,2]), tf.TensorShape([]), tf.TensorShape([])) )\n",
        "ds = ds.padded_batch(BATCH_SIZE, padded_shapes=([], [None, 2], [], []))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIxTrQG5spNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = next(iter(ds.take(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-4gO25hgeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "eafe149d-29a5-48dd-d7c2-c20969be5865"
      },
      "source": [
        "es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=49, shape=(4,), dtype=int64, numpy=array([ 2303940, 26325442,  1364426, 11454181])>,\n",
              " <tf.Tensor: id=50, shape=(4, 8, 2), dtype=int32, numpy=\n",
              " array([[[248013,    327],\n",
              "         [289254,    105],\n",
              "         [897795,    368],\n",
              "         [161834,    369],\n",
              "         [     0,      0],\n",
              "         [     0,      0],\n",
              "         [     0,      0],\n",
              "         [     0,      0]],\n",
              " \n",
              "        [[943059,    374],\n",
              "         [943821,     45],\n",
              "         [947422,    192],\n",
              "         [950139,    368],\n",
              "         [945437,    372],\n",
              "         [937926,     27],\n",
              "         [807501,    199],\n",
              "         [953043,     68]],\n",
              " \n",
              "        [[940762,     84],\n",
              "         [945313,    141],\n",
              "         [941896,    229],\n",
              "         [947689,     80],\n",
              "         [945785,    187],\n",
              "         [949732,    314],\n",
              "         [949275,    331],\n",
              "         [950077,    141]],\n",
              " \n",
              "        [[  6177,     83],\n",
              "         [921423,     83],\n",
              "         [  4922,     81],\n",
              "         [  4922,     81],\n",
              "         [  6177,     83],\n",
              "         [  4922,     81],\n",
              "         [     0,      0],\n",
              "         [     0,      0]]], dtype=int32)>,\n",
              " <tf.Tensor: id=51, shape=(4,), dtype=int32, numpy=array([4, 8, 8, 6], dtype=int32)>,\n",
              " <tf.Tensor: id=52, shape=(4,), dtype=int32, numpy=array([941960,  85269, 935222, 620065], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4KAUDhPFukc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "fe106352-c8a0-432c-f1d7-445221622243"
      },
      "source": [
        "model = keras.Sequential([\n",
        "             layers.Embedding(P+1, D, weights=[np_prod_embedding], mask_zero=True, trainable=False),\n",
        "             layers.LSTM(5, return_sequences=False)   \n",
        "              ]\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:3985: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXfU2unYGbtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0223494f-f121-480e-a1a8-aeb1d2282642"
      },
      "source": [
        "model.call(es[1][:,:, 0])[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=2276, shape=(5,), dtype=float32, numpy=\n",
              "array([-0.07150709,  0.03244724,  0.03638037,  0.00304948,  0.0632699 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO4XQd2qQaMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = keras.Sequential([\n",
        "             layers.Embedding(M+1, D, mask_zero=True) , \n",
        "             layers.GRU(5, return_sequences=True)   \n",
        "              ]\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coe3v1EeQk2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9764bc7a-491d-464e-ef0c-5f631837ba54"
      },
      "source": [
        "model2.call(es[1][:,:, 1])[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=4314, shape=(8, 5), dtype=float32, numpy=\n",
              "array([[-0.00922142, -0.00215422, -0.00039112, -0.01324965,  0.00112781],\n",
              "       [-0.02165597,  0.00167335,  0.02558472, -0.00678662,  0.00878757],\n",
              "       [-0.00644116, -0.01661966, -0.00038713, -0.00288206, -0.01866435],\n",
              "       [-0.04474729, -0.02402742,  0.03631931,  0.0271406 ,  0.02189269],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqONegtkcDx_",
        "colab_type": "text"
      },
      "source": [
        "## 모델 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fLs9ZDpa9v",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "def initialize_lstm(num_layers, num_units, decay):\n",
        "  \"\"\"\n",
        "  Initialize LSTM layers.\n",
        "\n",
        "  :param num_layers: the number of layers.\n",
        "  :param num_units: the number of hidden units in each cell.\n",
        "  :param decay: an L2 decay parameter for regularization.\n",
        "  :return: a sequence of LSTM layers.\n",
        "  \"\"\"\n",
        "  lstm = keras.Sequential()\n",
        "  for _ in range(num_layers):\n",
        "    lstm.add(layers.LSTM(num_units, return_sequences=True,\n",
        "            kernel_regularizer=reg.l2(decay),\n",
        "            bias_regularizer=reg.l2(decay),\n",
        "            activation='sigmoid'))\n",
        "  return lstm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj0JCpmFY2S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_dense_layer(num_units, decay):\n",
        "  \"\"\"\n",
        "  Initialize a dense layer which follows a sequence of LSTM layers.\n",
        "\n",
        "  :param num_units: the number of units of the output.\n",
        "  :param decay: an L2 decay parameter for regularization.\n",
        "  :return: the initialized dense layer.\n",
        "  \"\"\"\n",
        "  return layers.Dense(num_units,\n",
        "                kernel_regularizer=reg.l2(decay),\n",
        "                bias_regularizer=reg.l2(decay))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEtFlOiY-Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_embedding(num_entries, num_units, decay):\n",
        "  \"\"\"\n",
        "  Initialize an embedding layer.\n",
        "\n",
        "  :param num_entries: the number of entries whose embeddings to be learned.\n",
        "  :param num_units: the number of units of each embedding.\n",
        "  :param decay: an L2 decay parameter for regularization.\n",
        "  :return: the initialized embedding layer.\n",
        "  \"\"\"\n",
        "  embedding = layers.Embedding(\n",
        "      num_entries, num_units, embeddings_regularizer=reg.l2(decay))\n",
        "  # embedding(0)  # initialize the embeddings\n",
        "  return embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_8RD_XTZEgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_pretrained_embedding(numpy_mat, trainable=False):\n",
        "  \"\"\"\n",
        "  Initialize embedding layer initialized from exteranl numpy mat\n",
        "  \"\"\"\n",
        "  embedding = layers.Embedding(\n",
        "      numpy_mat.shape[0], numpy_mat.shape[1], weights=[numpy_mat], trainable=trainable)\n",
        "  return embedding  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZr9IRWFKPi",
        "colab_type": "text"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FM_AP4cZ4XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(keras.Model):\n",
        "  \"\"\"\n",
        "  Abstract model for recommendation.\n",
        "  \"\"\"\n",
        "  is_trainable = None\n",
        "\n",
        "  def __init__(self, embeddings):\n",
        "    \"\"\"\n",
        "    Class initializer.\n",
        "\n",
        "    :param embeddings: numpy matrix shape(P+1, D).\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.embeddings = load_pretrained_embedding(embeddings)\n",
        "\n",
        "  def call(self, inputs, candidates):\n",
        "    \"\"\"\n",
        "    Run forward propagation to produce outputs.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param candidates: a tuple of input tensors for candidates.\n",
        "    :return: the predicted scores for all candidates.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  @tf.function\n",
        "  def _lookup_features(self, seqs):\n",
        "    \"\"\"\n",
        "    Look up the feature vectors of all items in sequences.\n",
        "\n",
        "    :param seqs: the behavioral sequences for predictions.\n",
        "    :return: the feature vectors.\n",
        "    \"\"\"\n",
        "    return self.embeddings(seqs)\n",
        "\n",
        "  @tf.function\n",
        "  def eval_loss(self, inputs, labels):\n",
        "    \"\"\"\n",
        "    Evaluate the loss value for current inputs.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param labels: true labels of the given inputs.\n",
        "    :return: the calculated loss.\n",
        "    \"\"\"\n",
        "    return 0.\n",
        "\n",
        "  @tf.function\n",
        "  def predict_top_k(self, inputs, candidates, k):\n",
        "    \"\"\"\n",
        "    Return the top K recommendations among given candidates.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param candidates: a tuple of input tensors for candidates.\n",
        "    :param k: the number of items to recommend.\n",
        "    :return: the top K items with the highest scores.\n",
        "    \"\"\"\n",
        "    predictions = self.call(inputs, candidates)\n",
        "    return tf.nn.top_k(predictions, k, sorted=True)\n",
        "\n",
        "  @tf.function\n",
        "  def eval_accuracy(self, inputs, candidates, labels, k):\n",
        "    \"\"\"\n",
        "    Evaluate the accuracy of given inputs and labels.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param candidates: a tuple of input tensors for candidates.\n",
        "    :param labels: true labels of the given inputs.\n",
        "    :param k: the number of items to recommend.\n",
        "    :return: the calculated accuracy.\n",
        "    \"\"\"\n",
        "    predictions = self.predict_top_k(inputs, candidates, k)[1]\n",
        "    compared = tf.equal(tf.expand_dims(labels, axis=1), predictions)\n",
        "    corrects = tf.reduce_sum(tf.cast(compared, dtype=tf.float32), axis=1)\n",
        "    return tf.reduce_mean(corrects)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsISilo6FGh9",
        "colab_type": "text"
      },
      "source": [
        "#### BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6SU27MawhXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseModel(Model):\n",
        "  \"\"\"\n",
        "  Base model for recommendation, which has no learnable parameters.\n",
        "  \"\"\"\n",
        "  is_trainable = False\n",
        "\n",
        "  def __init__(self, embeddings, mode='average'):\n",
        "    \"\"\"\n",
        "    Class initializer.\n",
        "\n",
        "    :param embeddings: embedding vectors of all items.\n",
        "    :param mode: the prediction mode of this model: average or last.\n",
        "    \"\"\"\n",
        "    super().__init__(embeddings)\n",
        "    self.mode = mode\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, inputs, candidates):\n",
        "    \"\"\"\n",
        "    Run forward propagation to produce outputs.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param candidates: a tuple of input tensors for candidates.\n",
        "    :return: the predicted scores for all candidates.\n",
        "    \"\"\"\n",
        "    mid, x, len, label = inputs\n",
        "    orders = x[:, :, 0]\n",
        "    orders_x = self._lookup_features(orders)\n",
        "    cands_x = candidates[0]\n",
        "    len = tf.cast(len, tf.float32)\n",
        "\n",
        "    if self.mode == 'average':\n",
        "        out = tf.reduce_sum(orders_x, axis=1)\n",
        "        out /= tf.expand_dims(len, axis=1)\n",
        "    elif self.mode == 'last':\n",
        "        out = orders_x[:, -1, :]\n",
        "    else:\n",
        "        raise ValueError(self.mode)\n",
        "    return tf.matmul(out, cands_x, transpose_b=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVip-xlSEkd5",
        "colab_type": "text"
      },
      "source": [
        "#### 테스트 BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQLJloxPfKC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = BaseModel(np_prod_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhQkbavQfp-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prod_embs = tf.convert_to_tensor(np_prod_embedding, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXSg9m60fl61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candidates = (prod_embs, None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXzk1yJ5jtQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model(es, candidates)\n",
        "base_model.eval_accuracy(es, candidates, es[3], 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMv_hVKWj3Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33a10633-6120-4032-f8bb-43ac5b639869"
      },
      "source": [
        "np.dot(np_prod_embedding[913305], np_prod_embedding[941960])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.90099144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9-7ZZ9yEwO0",
        "colab_type": "text"
      },
      "source": [
        "#### RNN1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ssqB5uV2bWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN1(Model):\n",
        "  \"\"\"\n",
        "  RNN 1 model for recommendation, which uses none of important techniques.\n",
        "  \"\"\"\n",
        "  is_trainable = True\n",
        "\n",
        "  def __init__(self, embeddings, num_units=32, num_layers=1, decay=0):\n",
        "    \"\"\"\n",
        "    Class initializer.\n",
        "\n",
        "    :param embeddings: embedding vectors of all items.\n",
        "    :param num_units: the number of hidden units in each LSTM cell.\n",
        "    :param num_layers: the number of LSTM layers.\n",
        "    :param decay: an L2 decay parameter for regularization.\n",
        "    \"\"\"\n",
        "    super().__init__(embeddings)\n",
        "    self.lstm = initialize_lstm(num_layers, num_units, decay)\n",
        "    self.linear = initialize_dense_layer(embeddings.shape[1], decay)\n",
        "    self.samples = 'full'\n",
        "    self.softmax_bias = tf.zeros(embeddings.shape[0])\n",
        "    self.categories = None\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, inputs, candidates):\n",
        "    \"\"\"\n",
        "    Run forward propagation to produce outputs.\n",
        "\n",
        "    :param inputs: a tuple of input tensors for predictions.\n",
        "    :param candidates: a tuple of input tensors for candidates.\n",
        "    :return: the predicted scores for all candidates.\n",
        "    \"\"\"\n",
        "    users, x, len, orders, clicks = inputs\n",
        "    orders = self._lookup_features(orders)\n",
        "    orders = self.lstm(orders)\n",
        "    clicks = self._lookup_features(clicks)\n",
        "    out = self._run_attention(users, orders, clicks)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    cands_x, cands_c = candidates\n",
        "    cands_v = self._lookup_candidates(cands_x, cands_c)\n",
        "    return tf.matmul(out, tf.transpose(cands_v))\n",
        "\n",
        "  @tf.function\n",
        "  def train(self, inputs, labels, optimizer):\n",
        "      \"\"\"\n",
        "      Train the current model by a single batch.\n",
        "\n",
        "      :param inputs: a tuple of input tensors for predictions.\n",
        "      :param labels: true labels of the given inputs.\n",
        "      :param optimizer: an optimizer to apply.\n",
        "      :return: the current training loss.\n",
        "      \"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "          loss = self.eval_loss(inputs, labels)\n",
        "      trainable_variables = self.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "      return loss\n",
        "\n",
        "  @tf.function\n",
        "  def eval_loss(self, inputs, labels):\n",
        "      \"\"\"\n",
        "      Evaluate the loss value for current inputs.\n",
        "\n",
        "      :param inputs: a tuple of input tensors for predictions.\n",
        "      :param labels: true labels of the given inputs.\n",
        "      :return: the calculated loss.\n",
        "      \"\"\"\n",
        "      logits = self.call(inputs, (self.embeddings, self.categories))\n",
        "      if self.samples == 'full':\n",
        "          return self._eval_full_loss(logits, labels)\n",
        "      elif isinstance(self.samples, int):\n",
        "          return self._eval_sampled_loss(logits, labels)\n",
        "      else:\n",
        "          raise ValueError()\n",
        "\n",
        "  @tf.function\n",
        "  def _run_attention(self, users, vec_orders, vec_clicks):\n",
        "      \"\"\"\n",
        "      Run an attention mechanism for getting an output.\n",
        "\n",
        "      :param users: users in the given inputs.\n",
        "      :param vec_orders: the output (hidden) vectors of orders.\n",
        "      :param vec_clicks: the output (hidden) vectors of clicks.\n",
        "      :return: the chosen vector.\n",
        "      \"\"\"\n",
        "      return vec_orders[:, -1, :]\n",
        "\n",
        "  @tf.function\n",
        "  def _lookup_candidates(self, embeddings, categories):\n",
        "      \"\"\"\n",
        "      Look up candidate vectors by embeddings and categories.\n",
        "\n",
        "      :param embeddings: the embeddings of candidates.\n",
        "      :param categories: the categories of candidates.\n",
        "      :return: the chosen vectors.\n",
        "      \"\"\"\n",
        "      return embeddings\n",
        "\n",
        "  @tf.function\n",
        "  def _eval_full_loss(self, logits, labels):\n",
        "      \"\"\"\n",
        "      Evaluate the full loss when training.\n",
        "\n",
        "      :param logits: logits of the current input.\n",
        "      :param labels: labels of the current input.\n",
        "      :return: the calculated loss.\n",
        "      \"\"\"\n",
        "      return tf.reduce_mean(\n",
        "          tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "              labels=labels, logits=logits))\n",
        "\n",
        "  @tf.function\n",
        "  def _eval_sampled_loss(self, logits, labels):\n",
        "      \"\"\"\n",
        "      Evaluate the sampled loss when training.\n",
        "\n",
        "      :param logits: logits of the current input.\n",
        "      :param labels: labels of the current input.\n",
        "      :return: the calculated loss.\n",
        "      \"\"\"\n",
        "      c_vectors = self._lookup_candidates(self.embeddings, self.cands_c)\n",
        "      return tf.reduce_mean(\n",
        "          tf.nn.sampled_softmax_loss(\n",
        "              labels=tf.expand_dims(labels, 1),\n",
        "              inputs=logits,\n",
        "              weights=c_vectors,\n",
        "              biases=self.softmax_bias,\n",
        "              num_sampled=self.samples,\n",
        "              num_classes=c_vectors.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofA49Yz_2cx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN2(RNN1):\n",
        "    \"\"\"\n",
        "    RNN 2 model for recommendation, which uses category information.\n",
        "    \"\"\"\n",
        "    def __init__(self, embeddings, categories, emb_way='mean', num_units=32,\n",
        "                 num_layers=1, decay=0):\n",
        "        \"\"\"\n",
        "        Class initializer.\n",
        "\n",
        "        :param embeddings: embedding vectors of all items.\n",
        "        :param categories: multi-hot categories of all items.\n",
        "        :param emb_way: how to get embedding vectors of items.\n",
        "        :param num_units: the number of hidden units in each LSTM cell.\n",
        "        :param num_layers: the number of LSTM layers.\n",
        "        :param decay: an L2 decay parameter for regularization.\n",
        "        \"\"\"\n",
        "        super().__init__(embeddings, num_units, num_layers, decay)\n",
        "\n",
        "        nx = embeddings.shape[1]\n",
        "        nc = categories.shape[1]\n",
        "\n",
        "        self.categories = tf.convert_to_tensor(categories, dtype=tf.float32)\n",
        "        self.cat_embeddings = initialize_embedding(nc, nx, decay)\n",
        "        self.emb_way = emb_way\n",
        "        if emb_way == 'mlp':\n",
        "            self.emb_layer = layers.Dense(nx)\n",
        "\n",
        "    @tf.function\n",
        "    def _lookup_features(self, seqs):\n",
        "        \"\"\"\n",
        "        Look up the feature vectors of all items in sequences.\n",
        "\n",
        "        :param seqs: the behavioral sequences for predictions.\n",
        "        :return: the feature vectors.\n",
        "        \"\"\"\n",
        "        seq_index = tf.expand_dims(seqs, 2)\n",
        "        embeddings = tf.gather_nd(self.embeddings, seq_index)\n",
        "        categories = tf.gather_nd(self.categories, seq_index)\n",
        "        categories = normalize_categories(categories, axis=2)\n",
        "        cat_embeddings = self.cat_embeddings.weights[0]\n",
        "        cat_embeddings = tf.tensordot(categories, cat_embeddings, axes=[[2], [0]])\n",
        "        return self._combine_embeddings(embeddings, cat_embeddings)\n",
        "\n",
        "    @tf.function\n",
        "    def _lookup_candidates(self, embeddings, categories):  # N x D\n",
        "        \"\"\"\n",
        "        Look up candidate vectors by embeddings and categories.\n",
        "\n",
        "        :param embeddings: the embeddings of candidates.\n",
        "        :param categories: the categories of candidates.\n",
        "        :return: the chosen vectors.\n",
        "        \"\"\"\n",
        "        categories = normalize_categories(categories, axis=1)\n",
        "        cat_embeddings = self.cat_embeddings.weights[0]\n",
        "        cat_embeddings = tf.matmul(categories, cat_embeddings)\n",
        "        return self._combine_embeddings(embeddings, cat_embeddings)\n",
        "\n",
        "    @tf.function\n",
        "    def _combine_embeddings(self, embeddings, cat_embeddings):\n",
        "        \"\"\"\n",
        "        Combine vectors of titles and categories to get representations.\n",
        "\n",
        "        :param embeddings: embedding vectors learned for titles.\n",
        "        :param cat_embeddings: embedding vectors for categories.\n",
        "        :return: the final representations of items.\n",
        "        \"\"\"\n",
        "        if self.emb_way == 'mean':\n",
        "            return layers.average([embeddings, cat_embeddings])\n",
        "        elif self.emb_way == 'mlp':\n",
        "            out = tf.concat([embeddings, cat_embeddings], axis=-1)\n",
        "            return act.tanh(self.emb_layer(out))\n",
        "        else:\n",
        "            raise ValueError()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_i3xQFuQk2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=8192\n",
        "server_id = 'gcp'\n",
        "use_image=True\n",
        "data_size=\"small\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOfDziXmQpZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp_path = '/content/sp_s10M_v{}.model'.format(vocab_size)\n",
        "dcate_info_path = '/content/dcate_info'\n",
        "tf_data_path = 'gs://recom-test/prod_clf/tf_data_v{}'.format(vocab_size)\n",
        "\n",
        "#gdrive/My Drive/data/tb_logs/prod_clf/titles_img_4096\n",
        "tensor_board_path = 'gdrive/My Drive/data/prod_clf/tb_logs/titles_{}_v{}_{}'.format( \n",
        "                                        \"only\" if use_image==False else \"image\", \n",
        "                                        vocab_size, data_size)\n",
        "checkpoint_path = \"gdrive/My Drive/data/prod_clf/checkpoints/title_{}_v{}_{}\".format(\n",
        "                                        \"only\" if use_image==False else \"image\", \n",
        "                                        vocab_size, data_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI5LfXlUQ1wm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c69cfcb7-2062-41e0-df28-54d7403347ad"
      },
      "source": [
        "print(\"v{}-titles-{}-{}\".format(vocab_size, \"only\" if use_image==False else \"image\", data_size))\n",
        "print(sp_path)\n",
        "print(dcate_info_path)\n",
        "print(tf_data_path)\n",
        "print(tensor_board_path)\n",
        "print(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v8192-titles-image-small\n",
            "/content/sp_s10M_v8192.model\n",
            "/content/dcate_info\n",
            "gs://recom-test/prod_clf/tf_data_v8192\n",
            "gdrive/My Drive/data/prod_clf/tb_logs/titles_image_v8192_small\n",
            "gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUvIwCEQ9Ofw",
        "colab_type": "text"
      },
      "source": [
        "SentencePiece 모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBf3QTJG7doK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "abfc5a5d-a48a-4ebf-9117-7ce20b2190b5"
      },
      "source": [
        "!gsutil cp gs://recom-test/prod_clf/sentence_piece_model/sp_s10M_v8192.* ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://recom-test/prod_clf/sentence_piece_model/sp_s10M_v8192.model...\n",
            "Copying gs://recom-test/prod_clf/sentence_piece_model/sp_s10M_v8192.vocab...\n",
            "/ [2 files][501.8 KiB/501.8 KiB]                                                \n",
            "Operation completed over 2 objects/501.8 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNdbDNE5y74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86668f77-c264-46cf-ffc8-19281ae30025"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(sp_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDvhaWTM8i9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fd1c549-c8db-4906-ae48-eeb7ce5d5522"
      },
      "source": [
        "sp.GetPieceSize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSsZnF75RI_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0f1451aa-6ec8-408b-e093-b2019d6ed523"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Oct 15 05:42:45 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcqwbWWP9gxm",
        "colab_type": "text"
      },
      "source": [
        "dcate 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egIv66IHRhCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7fd5b2b9-a4ff-451a-b240-43e6356aa165"
      },
      "source": [
        "!gsutil cp gs://recom-test/prod_clf/dcate_info ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://recom-test/prod_clf/dcate_info...\n",
            "/ [1 files][825.7 KiB/825.7 KiB]                                                \n",
            "Operation completed over 1 objects/825.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6_jR4Xr9Fdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fs = gcsfs.GCSFileSystem(project='eighth-edge-810')\n",
        "# with fs.open(dcate_info_path) as f:\n",
        "#   dcate_df = pd.read_csv(f)\n",
        "\n",
        "dcate_df = pd.read_csv(dcate_info_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMKw5XnA_AR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcates = dcate_df[dcate_df.use_yn == 'Y']['dcate_cd']\n",
        "dcates.reset_index(drop=True, inplace=True)\n",
        "dcate_to_index = pd.Series(dcates.index, index=dcates.values, name='dc2i')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZzImU_riOKD",
        "colab_type": "text"
      },
      "source": [
        "### dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yQ3CUSsV4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=2048\n",
        "# BATCH_SIZE=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLMFBp1JSlMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3bf738b4-87cf-4884-caf8-2a125bd89aa3"
      },
      "source": [
        "tf.io.matching_files(os.path.join(tf_data_path, \"data-000[1]-00[1-2].tfrecords\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=287, shape=(2,), dtype=string, numpy=\n",
              "array([b'gs://recom-test/prod_clf/tf_data_v8192/data-0001-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0001-002.tfrecords'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3pYZ2lMC6g",
        "colab_type": "text"
      },
      "source": [
        "####tfrecordset 파싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpHw4IsJfHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = None\n",
        "if data_size == \"small\":\n",
        "    train_files = tf.io.matching_files(os.path.join(tf_data_path,\"data-000[1-9]-001.tfrecords\"))\n",
        "elif data_size == \"big\":\n",
        "    train_files = tf.io.matching_files(os.path.join(tf_data_path,\"data-000[1-9]-*.tfrecords\"))\n",
        "else: assert False, \"data_size should specify exactly!!!\"\n",
        "valid_files = tf.io.matching_files(os.path.join(tf_data_path,\"data-0031-00[1-5].tfrecords\"))\n",
        "test_files = tf.concat([tf.io.matching_files(os.path.join(tf_data_path,\"data-0031-00[6-9].tfrecords\")), tf.io.matching_files(os.path.join(tf_data_path,\"data-0031-01?.tfrecords\"))], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_7ztPA8S2wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "67996d1e-f38a-4c80-d80a-0a7adbb60be1"
      },
      "source": [
        "train_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=289, shape=(9,), dtype=string, numpy=\n",
              "array([b'gs://recom-test/prod_clf/tf_data_v8192/data-0001-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0002-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0003-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0004-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0005-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0006-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0007-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0008-001.tfrecords',\n",
              "       b'gs://recom-test/prod_clf/tf_data_v8192/data-0009-001.tfrecords'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVyLO-y4n2FD",
        "colab_type": "text"
      },
      "source": [
        "##### 참고: https://www.tensorflow.org/guide/data_performance\n",
        "\n",
        "tf.data 성능 최적화\n",
        "\n",
        "- **L**: tf.data.Dataset.prefetch(): CPU에서 다음 데이터를 미리 준비\n",
        "- **T**: tf.data.Dataset.map(): 병렬 정도\n",
        "- **E**: tf.data.interleave()\n",
        "\n",
        "의문\n",
        "- tf.data.Dataset.shuffle(): 버퍼사이즈가 데이터셋 사이즈보다 작을 때\n",
        "> 최초에 buffer_size 만큼 읽어둔다.\n",
        "> 샘플을 생성시, 이 버퍼에서 랜덤샘플링하여 제공\n",
        "> 샘플링된 자리는 데이터셋에서 추가로 읽어서 채움\n",
        "> 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HrkyaSUOjLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_example_function(example_proto):\n",
        "  context_features = {\n",
        "      'prod_no': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
        "      'img_raw': tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "      'label': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
        "  }\n",
        "  sequence_features = {\n",
        "      'title': tf.io.FixedLenSequenceFeature([], dtype=tf.int64),\n",
        "  }\n",
        "  context_data, sequence_data = tf.io.parse_single_sequence_example(\n",
        "    serialized=example_proto,\n",
        "    context_features=context_features,\n",
        "    sequence_features=sequence_features)\n",
        "  \n",
        "  return {'prod_no': context_data['prod_no'],\n",
        "          # 'img_raw': context_data['img_raw'], \n",
        "          'img_raw': tf.io.decode_raw(context_data['img_raw'],tf.float32),\n",
        "          'title': tf.concat( [tf.constant([sp.GetPieceSize()], tf.int64), sequence_data['title'], tf.constant([sp.GetPieceSize()+1], tf.int64)], 0), \n",
        "          'label': context_data['label'],\n",
        "          'len': tf.shape(sequence_data['title'])[0]\n",
        "         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p277UJFhNIBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_max_length(x, max_length=256):\n",
        "  return x['len'] < max_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55z_KEuonXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(train_files).interleave(\n",
        "    lambda x: tf.data.TFRecordDataset(x).map(parse_example_function, num_parallel_calls=tf.data.experimental.AUTOTUNE),\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.shuffle(buffer_size=1024*1024)\n",
        "train_ds = train_ds.filter(filter_max_length)\n",
        "train_ds = train_ds.padded_batch(BATCH_SIZE, drop_remainder=True, padded_shapes=({'prod_no':[], 'img_raw':[256], 'title':[None], 'label':[], 'len':[]}))\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZIYzwijdjMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_ds = tf.data.Dataset.from_tensor_slices(valid_files).interleave(\n",
        "    lambda x: tf.data.TFRecordDataset(x).map(parse_example_function, num_parallel_calls=tf.data.experimental.AUTOTUNE),\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.filter(filter_max_length)\n",
        "valid_ds = valid_ds.padded_batch(BATCH_SIZE, drop_remainder=True, padded_shapes=({'prod_no':[], 'img_raw':[256], 'title':[None], 'label':[], 'len':[]}))\n",
        "valid_ds = valid_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt65xCt7MYFi",
        "colab_type": "text"
      },
      "source": [
        "##### 확인용 테스트 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71uYW-oaMcJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = next(iter(valid_ds.take(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqZeJ7FiMwIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "81b6daa3-2339-4878-caeb-4d599d3e10a7"
      },
      "source": [
        "es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'img_raw': <tf.Tensor: id=469, shape=(2048, 256), dtype=float32, numpy=\n",
              " array([[0.00813446, 0.        , 0.        , ..., 0.        , 0.00567395,\n",
              "         0.06752175],\n",
              "        [0.09760024, 0.07886583, 0.0092227 , ..., 0.0127738 , 0.0952163 ,\n",
              "         0.01787292],\n",
              "        [0.08291596, 0.00249639, 0.        , ..., 0.00221992, 0.08122448,\n",
              "         0.03835855],\n",
              "        ...,\n",
              "        [0.00361221, 0.00774941, 0.        , ..., 0.01171967, 0.        ,\n",
              "         0.06940682],\n",
              "        [0.03074229, 0.00615553, 0.00955817, ..., 0.07541917, 0.0139981 ,\n",
              "         0.09474275],\n",
              "        [0.13484463, 0.01376132, 0.00685129, ..., 0.        , 0.11674917,\n",
              "         0.07395013]], dtype=float32)>,\n",
              " 'label': <tf.Tensor: id=470, shape=(2048,), dtype=int64, numpy=array([ 706, 6179, 1302, ..., 2653,  720, 1837])>,\n",
              " 'len': <tf.Tensor: id=471, shape=(2048,), dtype=int32, numpy=array([ 8, 15,  8, ..., 30, 23,  7], dtype=int32)>,\n",
              " 'prod_no': <tf.Tensor: id=472, shape=(2048,), dtype=int64, numpy=\n",
              " array([258705656, 110806613, 254630268, ..., 259024859, 247490464,\n",
              "        143974779])>,\n",
              " 'title': <tf.Tensor: id=473, shape=(2048, 57), dtype=int64, numpy=\n",
              " array([[8192, 4447, 4250, ...,    0,    0,    0],\n",
              "        [8192, 1094, 2477, ...,    0,    0,    0],\n",
              "        [8192,  885, 3331, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [8192,  368, 1563, ...,    0,    0,    0],\n",
              "        [8192,    5, 6214, ...,    0,    0,    0],\n",
              "        [8192,  338,  343, ...,    0,    0,    0]])>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Mnx803BPMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e18fdf91-dea5-467a-a5cd-66205076f1bd"
      },
      "source": [
        "# tf.io.decode_raw(es['img_raw'],tf.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=13616, shape=(4, 256), dtype=float32, numpy=\n",
              "array([[0.00813446, 0.        , 0.        , ..., 0.        , 0.00567395,\n",
              "        0.06752175],\n",
              "       [0.09760024, 0.07886583, 0.0092227 , ..., 0.0127738 , 0.0952163 ,\n",
              "        0.01787292],\n",
              "       [0.08291596, 0.00249639, 0.        , ..., 0.00221992, 0.08122448,\n",
              "        0.03835855],\n",
              "       [0.0126124 , 0.        , 0.01110924, ..., 0.03826494, 0.        ,\n",
              "        0.10339396]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfbiSyOAsHOg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxYanq1wPGh",
        "colab_type": "text"
      },
      "source": [
        "## 모델\n",
        "\n",
        "Transformer 적용\n",
        "\n",
        "참고\n",
        "\n",
        "\n",
        "- TF 2.0 의 튜토리얼에서 코딩 참고 https://www.tensorflow.org/beta/tutorials/text/transformer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGRTInOtODj6",
        "colab_type": "text"
      },
      "source": [
        "#### Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "  \n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "  \n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions so that we can add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4tQryyZ4QDi5"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dVxS8OPI9uI0",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mytb1lPyOHLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd8bc6f0-3b59-4322-fb94-ced71105e45f"
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "## Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UJDEUHDUNUSO"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzZRXdO0mI48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7633a58a-2020-48bf-dada-541eb6f0b77e"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "### Decoder layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   Point wise feed forward networks\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "There are N decoder layers in the transformer.\n",
        "\n",
        "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SoX0-vd1hue",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ne2Bqx8k71l0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d7f66c4-59a5-46dd-9e6d-77be1ed752ce"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8QG9nueFQKXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc93f2a5-87b9-45e7-aecc-efb87e094deb"
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=4096)\n",
        "\n",
        "sample_encoder_output = sample_encoder(tf.random.uniform((64, 16)), \n",
        "                                       training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        " The `Decoder` consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5_d5-PLQXwY",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1jXoAMRZyvu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94efe1d8-fb75-4d8f-8ac9-f7c8897c82b3"
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000)\n",
        "\n",
        "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False, look_ahead_mask=None, \n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCEXpfYUNe0R",
        "colab_type": "text"
      },
      "source": [
        "## TransformerClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74brwAB3_G8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcate_siz = len(dcate_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98twaxLo-OWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use_image=True (이미지 활용)\n",
        "class TransformerClassifier(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               dcate_siz, rate=0.1, use_image=False):\n",
        "    super(TransformerClassifier, self).__init__()\n",
        "    \n",
        "    self.use_image = use_image\n",
        "    \n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "    self.dense3 = tf.keras.layers.Dense(64, activation='relu')\n",
        "    self.drop1 = tf.keras.layers.Dropout(rate)\n",
        "    self.drop2 = tf.keras.layers.Dropout(rate)\n",
        "    self.drop3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    self.dcate = tf.keras.layers.Dense(dcate_siz)\n",
        "    \n",
        "  def call(self, inp, training, enc_padding_mask):\n",
        "    enc_output = self.encoder(inp['title'], training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    # print(enc_output.shape)\n",
        "    seq_len = tf.shape(enc_output)[1]\n",
        "    x = enc_output[:, 0, :] if self.use_image==False else tf.concat([enc_output[:, 0, :], inp['img_raw']], axis=1)\n",
        "    x = self.dense1(x)\n",
        "    x = self.drop1(x, training=training)\n",
        "    x = self.dense2(x)\n",
        "    x = self.drop2(x, training=training)\n",
        "    x = self.dense3(x)\n",
        "    x = self.drop3(x, training=training)\n",
        "        \n",
        "    dcate = self.dcate(x)\n",
        "    \n",
        "    return dcate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gqa4G4gzvzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_transformer = TransformerClassifier(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=sp.GetPieceSize(), \n",
        "    dcate_siz=len(dcate_to_index)\n",
        "    )\n",
        "\n",
        "input = {\n",
        "    'title': tf.random.uniform((4, 62)),\n",
        "    'img_raw':   tf.random.uniform((4, 1024))\n",
        "}\n",
        "\n",
        "\n",
        "fn_out = sample_transformer(input, training=False, \n",
        "                               enc_padding_mask=None \n",
        "                               )\n",
        "\n",
        "#fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FnkXWJcBU2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "887b0f0c-b2d4-4a3b-a68d-38ab6b65851f"
      },
      "source": [
        "fn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=1137, shape=(4, 7232), dtype=float32, numpy=\n",
              "array([[ 0.11284157,  0.05871063,  0.06392423, ..., -0.00744636,\n",
              "        -0.10323505,  0.03717372],\n",
              "       [ 0.11284157,  0.05871063,  0.06392423, ..., -0.00744636,\n",
              "        -0.10323505,  0.03717372],\n",
              "       [ 0.11284157,  0.05871063,  0.06392423, ..., -0.00744636,\n",
              "        -0.10323505,  0.03717372],\n",
              "       [ 0.11284157,  0.05871063,  0.06392423, ..., -0.00744636,\n",
              "        -0.10323505,  0.03717372]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = sp.GetPieceSize()+2\n",
        "\n",
        "dropout_rate = 0.1\n",
        "dcate_siz = len(dcate_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWTcuJKMtaLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(tensor_board_path):\n",
        "  os.makedirs(tensor_board_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qITH8vuUvQyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e6083cbb-837a-4757-f35e-5068914f3a69"
      },
      "source": [
        "#!ls -al 'gdrive/My Drive/data/tb_logs/prod_clf/titles_only_4096'\n",
        "!ls -al 'gdrive/My Drive/data/checkpoints'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Oct 10 01:53 .\n",
            "drwxr-xr-x 4 root root 4096 Oct 10 08:41 ..\n",
            "drwxr-xr-x 2 root root 4096 Oct 10 08:04 train_prod_clf_title_only\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwK2t3mnoFVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensor_board_path = 'gdrive/My Drive/data/tb_logs/prod_clf/titles_img_4096'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3msfe8gB1G-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e2c3d93a-a7ab-468f-f00e-ec9e15bb6fd6"
      },
      "source": [
        "# !ls -al 'gdrive/My Drive/data/tb_logs/prod_clf/titles_only_4096'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Oct 10 08:44 .\n",
            "drwxr-xr-x 3 root root 4096 Oct 10 08:41 ..\n",
            "drwxr-xr-x 4 root root 4096 Oct 10 08:44 20191010-084446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qUo9MlIwHRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "5dd4c3f2-339b-44ff-d9a7-fd1af75db34c"
      },
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# import os\n",
        "# if not os.path.exists(tensor_board_path):\n",
        "#   os.makedirs(tensor_board_path)\n",
        "  \n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(tensor_board_path))\n",
        "\n",
        "# get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-10 08:44:19--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.225.101.71, 52.2.145.235, 52.200.233.201, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.225.101.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  43.4MB/s    in 0.3s    \n",
            "\n",
            "2019-10-10 08:44:19 (43.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://be3dc4cc.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f33ZCgvHpPdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "667a3cbd-39c8-4bb5-ef01-eeda1b0a1501"
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(1000000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQQ2AN41AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5NPQHhkeya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7qzVdkRStc-",
        "colab_type": "text"
      },
      "source": [
        "### optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bz9U6liSw5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "#     from_logits=True, reduction='none')\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  loss = 0.0\n",
        "  loss += loss_object(real, pred)\n",
        "  # for key in keys:\n",
        "  #   loss += loss_object(reals[key], preds[key])\n",
        "  #   #loss += tf.reduce_mean(loss_object(reals[key], preds[key]))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = TransformerClassifier(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, dcate_siz=dcate_siz, \n",
        "              rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "    \n",
        "  return enc_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKpoA6q1sJFj",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_OsoPboH9yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys=['dcate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(x):  \n",
        "  enc_padding_mask = create_masks(x['title'])\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = transformer(x, True, enc_padding_mask)\n",
        "    loss = loss_function(x['label'], logits)\n",
        "    \n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  return loss, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chbdNlTx5Ehf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def predict_step(x):\n",
        "  enc_padding_mask = create_masks(x['title'])\n",
        "  logits = transformer(x, False, enc_padding_mask)\n",
        "\n",
        "  return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAKi2iuHpjuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = os.path.join(tensor_board_path, current_time)\n",
        "train_log_dir = os.path.join(train_log_dir, 'train')\n",
        "test_log_dir = os.path.join(tensor_board_path, current_time)\n",
        "test_log_dir = os.path.join(test_log_dir, 'test')\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a66cc9da-a0da-4019-fdc1-30e231304136"
      },
      "source": [
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "train_acc_metric = {'dcate':tf.keras.metrics.SparseCategoricalAccuracy()}\n",
        "valid_acc_metric = {'dcate':tf.keras.metrics.SparseCategoricalAccuracy()}\n",
        "\n",
        "total_steps = 0\n",
        "PRINT_STEPS = 500\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  total_loss = 0\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, x) in enumerate(train_ds):\n",
        "    total_steps += 1\n",
        "    batch_loss, preds = train_step(x)\n",
        "    total_loss += batch_loss\n",
        "    \n",
        "    train_loss(batch_loss)\n",
        "\n",
        "    train_acc_metric['dcate'](x['label'], preds)\n",
        "\n",
        "    if (batch+1) % PRINT_STEPS == 0:\n",
        "      print('Epoch {} Batch {} total_step {} Loss {:.4f}'.format(epoch+1,\n",
        "                                                     batch+1,\n",
        "                                                     total_steps,\n",
        "                                                     train_loss.result()\n",
        "                                                  ))\n",
        "      print('Seen so far: {} samples'.format(total_steps * BATCH_SIZE))\n",
        "\n",
        "  with train_summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
        "    tf.summary.scalar('accuracy', train_acc_metric['dcate'].result(), step=epoch)\n",
        "     \n",
        "  train_acc = []\n",
        "  train_acc.append('{},acc:{}'.format('dcate', float(train_acc_metric['dcate'].result())))\n",
        "  train_acc_metric['dcate'].reset_states()\n",
        "  \n",
        "  print('Training loss {}, acc {} over epoch {}'.format(train_loss.result(), '\\t'.join(train_acc), epoch+1))\n",
        "  \n",
        "  for (batch, x) in enumerate(valid_ds):\n",
        "    valid_logits = predict_step(x)\n",
        "    valid_acc_metric['dcate'](x['label'], valid_logits) \n",
        "\n",
        "  with test_summary_writer.as_default():\n",
        "    tf.summary.scalar('accuracy', valid_acc_metric['dcate'].result(), step=epoch)\n",
        "\n",
        "  valid_acc = []      \n",
        "  valid_acc.append('{},acc:{}'.format('dcate', float(valid_acc_metric['dcate'].result())))\n",
        "  valid_acc_metric['dcate'].reset_states()\n",
        "    \n",
        "  print('Validation acc over epoch {}: {}'.format(epoch+1, '\\t'.join(valid_acc)))\n",
        "  \n",
        "  if (epoch + 1) % 3 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss 7.88450813293457, acc dcate,acc:0.009239527396857738 over epoch 1\n",
            "Validation acc over epoch 1: dcate,acc:0.03773773834109306\n",
            "Time taken for 1 epoch: 729.0867390632629 secs\n",
            "\n",
            "Training loss 6.104522705078125, acc dcate,acc:0.07023464143276215 over epoch 2\n",
            "Validation acc over epoch 2: dcate,acc:0.1461561918258667\n",
            "Time taken for 1 epoch: 642.6974456310272 secs\n",
            "\n",
            "Training loss 4.733044147491455, acc dcate,acc:0.154713973402977 over epoch 3\n",
            "Validation acc over epoch 3: dcate,acc:0.2323758453130722\n",
            "Saving checkpoint for epoch 3 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-1\n",
            "Time taken for 1 epoch: 642.4792604446411 secs\n",
            "\n",
            "Training loss 4.080524444580078, acc dcate,acc:0.2145056277513504 over epoch 4\n",
            "Validation acc over epoch 4: dcate,acc:0.2847059965133667\n",
            "Time taken for 1 epoch: 635.1698656082153 secs\n",
            "\n",
            "Training loss 3.717193841934204, acc dcate,acc:0.2559772729873657 over epoch 5\n",
            "Validation acc over epoch 5: dcate,acc:0.3227759301662445\n",
            "Time taken for 1 epoch: 635.0918197631836 secs\n",
            "\n",
            "Training loss 3.474041223526001, acc dcate,acc:0.2882338762283325 over epoch 6\n",
            "Validation acc over epoch 6: dcate,acc:0.34214308857917786\n",
            "Saving checkpoint for epoch 6 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-2\n",
            "Time taken for 1 epoch: 633.184582233429 secs\n",
            "\n",
            "Training loss 3.2995777130126953, acc dcate,acc:0.31125539541244507 over epoch 7\n",
            "Validation acc over epoch 7: dcate,acc:0.3626348674297333\n",
            "Time taken for 1 epoch: 633.7404446601868 secs\n",
            "\n",
            "Training loss 3.165400266647339, acc dcate,acc:0.329679936170578 over epoch 8\n",
            "Validation acc over epoch 8: dcate,acc:0.3756864070892334\n",
            "Time taken for 1 epoch: 634.2138357162476 secs\n",
            "\n",
            "Training loss 3.061335802078247, acc dcate,acc:0.34521374106407166 over epoch 9\n",
            "Validation acc over epoch 9: dcate,acc:0.38840973377227783\n",
            "Saving checkpoint for epoch 9 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-3\n",
            "Time taken for 1 epoch: 632.0343337059021 secs\n",
            "\n",
            "Training loss 2.963730573654175, acc dcate,acc:0.35948067903518677 over epoch 10\n",
            "Validation acc over epoch 10: dcate,acc:0.4053514897823334\n",
            "Time taken for 1 epoch: 630.239795923233 secs\n",
            "\n",
            "Training loss 2.861016035079956, acc dcate,acc:0.3743126392364502 over epoch 11\n",
            "Validation acc over epoch 11: dcate,acc:0.4131779968738556\n",
            "Time taken for 1 epoch: 634.4050233364105 secs\n",
            "\n",
            "Training loss 2.7855448722839355, acc dcate,acc:0.3855898082256317 over epoch 12\n",
            "Validation acc over epoch 12: dcate,acc:0.4234699308872223\n",
            "Saving checkpoint for epoch 12 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-4\n",
            "Time taken for 1 epoch: 633.9954974651337 secs\n",
            "\n",
            "Training loss 2.713038206100464, acc dcate,acc:0.3973919749259949 over epoch 13\n",
            "Validation acc over epoch 13: dcate,acc:0.4297715425491333\n",
            "Time taken for 1 epoch: 634.6221590042114 secs\n",
            "\n",
            "Training loss 2.6575405597686768, acc dcate,acc:0.40614211559295654 over epoch 14\n",
            "Validation acc over epoch 14: dcate,acc:0.43630531430244446\n",
            "Time taken for 1 epoch: 635.0929396152496 secs\n",
            "\n",
            "Training loss 2.6056315898895264, acc dcate,acc:0.41468313336372375 over epoch 15\n",
            "Validation acc over epoch 15: dcate,acc:0.4430932104587555\n",
            "Saving checkpoint for epoch 15 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-5\n",
            "Time taken for 1 epoch: 633.3953878879547 secs\n",
            "\n",
            "Training loss 2.5620999336242676, acc dcate,acc:0.4215179681777954 over epoch 16\n",
            "Validation acc over epoch 16: dcate,acc:0.4471875727176666\n",
            "Time taken for 1 epoch: 634.1568315029144 secs\n",
            "\n",
            "Training loss 2.524491310119629, acc dcate,acc:0.42765873670578003 over epoch 17\n",
            "Validation acc over epoch 17: dcate,acc:0.4520503878593445\n",
            "Time taken for 1 epoch: 632.211080789566 secs\n",
            "\n",
            "Training loss 2.491999626159668, acc dcate,acc:0.4331800043582916 over epoch 18\n",
            "Validation acc over epoch 18: dcate,acc:0.4554823637008667\n",
            "Saving checkpoint for epoch 18 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-6\n",
            "Time taken for 1 epoch: 631.7240474224091 secs\n",
            "\n",
            "Training loss 2.4590463638305664, acc dcate,acc:0.4381495714187622 over epoch 19\n",
            "Validation acc over epoch 19: dcate,acc:0.4597788453102112\n",
            "Time taken for 1 epoch: 631.2823057174683 secs\n",
            "\n",
            "Training loss 2.4300737380981445, acc dcate,acc:0.4438287615776062 over epoch 20\n",
            "Validation acc over epoch 20: dcate,acc:0.46177199482917786\n",
            "Time taken for 1 epoch: 634.5976884365082 secs\n",
            "\n",
            "Training loss 2.404110908508301, acc dcate,acc:0.4476504623889923 over epoch 21\n",
            "Validation acc over epoch 21: dcate,acc:0.46547210216522217\n",
            "Saving checkpoint for epoch 21 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-7\n",
            "Time taken for 1 epoch: 630.9462540149689 secs\n",
            "\n",
            "Training loss 2.379483699798584, acc dcate,acc:0.45220404863357544 over epoch 22\n",
            "Validation acc over epoch 22: dcate,acc:0.4688340425491333\n",
            "Time taken for 1 epoch: 631.9117000102997 secs\n",
            "\n",
            "Training loss 2.3584187030792236, acc dcate,acc:0.45624712109565735 over epoch 23\n",
            "Validation acc over epoch 23: dcate,acc:0.4689241051673889\n",
            "Time taken for 1 epoch: 633.3603529930115 secs\n",
            "\n",
            "Training loss 2.336556911468506, acc dcate,acc:0.45940035581588745 over epoch 24\n",
            "Validation acc over epoch 24: dcate,acc:0.4734106957912445\n",
            "Saving checkpoint for epoch 24 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-8\n",
            "Time taken for 1 epoch: 632.6684341430664 secs\n",
            "\n",
            "Training loss 2.320113182067871, acc dcate,acc:0.4618072807788849 over epoch 25\n",
            "Validation acc over epoch 25: dcate,acc:0.47583407163619995\n",
            "Time taken for 1 epoch: 632.6623413562775 secs\n",
            "\n",
            "Training loss 2.3020575046539307, acc dcate,acc:0.4659649133682251 over epoch 26\n",
            "Validation acc over epoch 26: dcate,acc:0.4764464199542999\n",
            "Time taken for 1 epoch: 632.2362213134766 secs\n",
            "\n",
            "Training loss 2.282832622528076, acc dcate,acc:0.4688912630081177 over epoch 27\n",
            "Validation acc over epoch 27: dcate,acc:0.4774329960346222\n",
            "Saving checkpoint for epoch 27 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-9\n",
            "Time taken for 1 epoch: 631.6382038593292 secs\n",
            "\n",
            "Training loss 2.2652933597564697, acc dcate,acc:0.47157400846481323 over epoch 28\n",
            "Validation acc over epoch 28: dcate,acc:0.4786536991596222\n",
            "Time taken for 1 epoch: 634.9665501117706 secs\n",
            "\n",
            "Training loss 2.2498514652252197, acc dcate,acc:0.47458600997924805 over epoch 29\n",
            "Validation acc over epoch 29: dcate,acc:0.48156338930130005\n",
            "Time taken for 1 epoch: 630.0580523014069 secs\n",
            "\n",
            "Training loss 2.238995313644409, acc dcate,acc:0.4770185351371765 over epoch 30\n",
            "Validation acc over epoch 30: dcate,acc:0.4839167296886444\n",
            "Saving checkpoint for epoch 30 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-10\n",
            "Time taken for 1 epoch: 634.3355011940002 secs\n",
            "\n",
            "Training loss 2.223306894302368, acc dcate,acc:0.4800138473510742 over epoch 31\n",
            "Validation acc over epoch 31: dcate,acc:0.4848792850971222\n",
            "Time taken for 1 epoch: 632.9568886756897 secs\n",
            "\n",
            "Training loss 2.2095720767974854, acc dcate,acc:0.4816177189350128 over epoch 32\n",
            "Validation acc over epoch 32: dcate,acc:0.4847111999988556\n",
            "Time taken for 1 epoch: 634.2016878128052 secs\n",
            "\n",
            "Training loss 2.1963894367218018, acc dcate,acc:0.4843938946723938 over epoch 33\n",
            "Validation acc over epoch 33: dcate,acc:0.48711657524108887\n",
            "Saving checkpoint for epoch 33 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-11\n",
            "Time taken for 1 epoch: 630.0019550323486 secs\n",
            "\n",
            "Training loss 2.1863903999328613, acc dcate,acc:0.4864148795604706 over epoch 34\n",
            "Validation acc over epoch 34: dcate,acc:0.48732468485832214\n",
            "Time taken for 1 epoch: 629.9069519042969 secs\n",
            "\n",
            "Training loss 2.1738195419311523, acc dcate,acc:0.48843586444854736 over epoch 35\n",
            "Validation acc over epoch 35: dcate,acc:0.48927780985832214\n",
            "Time taken for 1 epoch: 631.816796541214 secs\n",
            "\n",
            "Training loss 2.1640007495880127, acc dcate,acc:0.49023327231407166 over epoch 36\n",
            "Validation acc over epoch 36: dcate,acc:0.4906986355781555\n",
            "Saving checkpoint for epoch 36 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-12\n",
            "Time taken for 1 epoch: 631.9005391597748 secs\n",
            "\n",
            "Training loss 2.1554343700408936, acc dcate,acc:0.49304839968681335 over epoch 37\n",
            "Validation acc over epoch 37: dcate,acc:0.4904004633426666\n",
            "Time taken for 1 epoch: 632.091299533844 secs\n",
            "\n",
            "Training loss 2.1424198150634766, acc dcate,acc:0.4939170479774475 over epoch 38\n",
            "Validation acc over epoch 38: dcate,acc:0.4926978051662445\n",
            "Time taken for 1 epoch: 629.8171303272247 secs\n",
            "\n",
            "Training loss 2.1342172622680664, acc dcate,acc:0.495373010635376 over epoch 39\n",
            "Validation acc over epoch 39: dcate,acc:0.4921894967556\n",
            "Saving checkpoint for epoch 39 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-13\n",
            "Time taken for 1 epoch: 633.7818601131439 secs\n",
            "\n",
            "Training loss 2.1246566772460938, acc dcate,acc:0.49705252051353455 over epoch 40\n",
            "Validation acc over epoch 40: dcate,acc:0.49422067403793335\n",
            "Time taken for 1 epoch: 630.4034171104431 secs\n",
            "\n",
            "Training loss 2.113983392715454, acc dcate,acc:0.49926701188087463 over epoch 41\n",
            "Validation acc over epoch 41: dcate,acc:0.49543535709381104\n",
            "Time taken for 1 epoch: 631.6837642192841 secs\n",
            "\n",
            "Training loss 2.1061062812805176, acc dcate,acc:0.5005739331245422 over epoch 42\n",
            "Validation acc over epoch 42: dcate,acc:0.49669408798217773\n",
            "Saving checkpoint for epoch 42 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-14\n",
            "Time taken for 1 epoch: 631.9466013908386 secs\n",
            "\n",
            "Training loss 2.099865674972534, acc dcate,acc:0.5028173327445984 over epoch 43\n",
            "Validation acc over epoch 43: dcate,acc:0.49699026346206665\n",
            "Time taken for 1 epoch: 637.1266086101532 secs\n",
            "\n",
            "Training loss 2.0904903411865234, acc dcate,acc:0.5037605166435242 over epoch 44\n",
            "Validation acc over epoch 44: dcate,acc:0.4974305331707001\n",
            "Time taken for 1 epoch: 632.2011840343475 secs\n",
            "\n",
            "Training loss 2.0806798934936523, acc dcate,acc:0.505563497543335 over epoch 45\n",
            "Validation acc over epoch 45: dcate,acc:0.4988853633403778\n",
            "Saving checkpoint for epoch 45 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-15\n",
            "Time taken for 1 epoch: 629.3739941120148 secs\n",
            "\n",
            "Training loss 2.074521064758301, acc dcate,acc:0.5069504976272583 over epoch 46\n",
            "Validation acc over epoch 46: dcate,acc:0.4987873136997223\n",
            "Time taken for 1 epoch: 632.4306588172913 secs\n",
            "\n",
            "Training loss 2.0697059631347656, acc dcate,acc:0.508248507976532 over epoch 47\n",
            "Validation acc over epoch 47: dcate,acc:0.500732421875\n",
            "Time taken for 1 epoch: 631.2761874198914 secs\n",
            "\n",
            "Training loss 2.061535596847534, acc dcate,acc:0.5089659094810486 over epoch 48\n",
            "Validation acc over epoch 48: dcate,acc:0.49944567680358887\n",
            "Saving checkpoint for epoch 48 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-16\n",
            "Time taken for 1 epoch: 633.192164182663 secs\n",
            "\n",
            "Training loss 2.0531885623931885, acc dcate,acc:0.5108211636543274 over epoch 49\n",
            "Validation acc over epoch 49: dcate,acc:0.5002401471138\n",
            "Time taken for 1 epoch: 632.7370481491089 secs\n",
            "\n",
            "Training loss 2.0463144779205322, acc dcate,acc:0.5122915506362915 over epoch 50\n",
            "Validation acc over epoch 50: dcate,acc:0.5010986328125\n",
            "Time taken for 1 epoch: 631.3324294090271 secs\n",
            "\n",
            "Training loss 2.038501262664795, acc dcate,acc:0.5134494304656982 over epoch 51\n",
            "Validation acc over epoch 51: dcate,acc:0.5023093223571777\n",
            "Saving checkpoint for epoch 51 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-17\n",
            "Time taken for 1 epoch: 631.6021473407745 secs\n",
            "\n",
            "Training loss 2.032958745956421, acc dcate,acc:0.5146328806877136 over epoch 52\n",
            "Validation acc over epoch 52: dcate,acc:0.5021572709083557\n",
            "Time taken for 1 epoch: 632.3085932731628 secs\n",
            "\n",
            "Training loss 2.02644681930542, acc dcate,acc:0.5153669714927673 over epoch 53\n",
            "Validation acc over epoch 53: dcate,acc:0.5014728307723999\n",
            "Time taken for 1 epoch: 632.5507836341858 secs\n",
            "\n",
            "Training loss 2.019968032836914, acc dcate,acc:0.5173211693763733 over epoch 54\n",
            "Validation acc over epoch 54: dcate,acc:0.5034760236740112\n",
            "Saving checkpoint for epoch 54 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-18\n",
            "Time taken for 1 epoch: 631.0319182872772 secs\n",
            "\n",
            "Training loss 2.0144031047821045, acc dcate,acc:0.5182632803916931 over epoch 55\n",
            "Validation acc over epoch 55: dcate,acc:0.5046026706695557\n",
            "Time taken for 1 epoch: 633.9042747020721 secs\n",
            "\n",
            "Training loss 2.0086889266967773, acc dcate,acc:0.5191164016723633 over epoch 56\n",
            "Validation acc over epoch 56: dcate,acc:0.5049008131027222\n",
            "Time taken for 1 epoch: 632.0901136398315 secs\n",
            "\n",
            "Training loss 2.0040931701660156, acc dcate,acc:0.5201596617698669 over epoch 57\n",
            "Validation acc over epoch 57: dcate,acc:0.5054731369018555\n",
            "Saving checkpoint for epoch 57 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-19\n",
            "Time taken for 1 epoch: 635.2715599536896 secs\n",
            "\n",
            "Training loss 1.9984233379364014, acc dcate,acc:0.5208058953285217 over epoch 58\n",
            "Validation acc over epoch 58: dcate,acc:0.505567193031311\n",
            "Time taken for 1 epoch: 635.6274275779724 secs\n",
            "\n",
            "Training loss 1.993011713027954, acc dcate,acc:0.5221083760261536 over epoch 59\n",
            "Validation acc over epoch 59: dcate,acc:0.5051249265670776\n",
            "Time taken for 1 epoch: 634.9625856876373 secs\n",
            "\n",
            "Training loss 1.987760305404663, acc dcate,acc:0.5232828855514526 over epoch 60\n",
            "Validation acc over epoch 60: dcate,acc:0.5066018104553223\n",
            "Saving checkpoint for epoch 60 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-20\n",
            "Time taken for 1 epoch: 632.9994082450867 secs\n",
            "\n",
            "Training loss 1.983904480934143, acc dcate,acc:0.5240325331687927 over epoch 61\n",
            "Validation acc over epoch 61: dcate,acc:0.5064717531204224\n",
            "Time taken for 1 epoch: 639.4300096035004 secs\n",
            "\n",
            "Training loss 1.9792120456695557, acc dcate,acc:0.524617612361908 over epoch 62\n",
            "Validation acc over epoch 62: dcate,acc:0.5080026388168335\n",
            "Time taken for 1 epoch: 635.7336819171906 secs\n",
            "\n",
            "Training loss 1.9738743305206299, acc dcate,acc:0.5262092351913452 over epoch 63\n",
            "Validation acc over epoch 63: dcate,acc:0.5083208084106445\n",
            "Saving checkpoint for epoch 63 at gdrive/My Drive/data/prod_clf/checkpoints/title_image_v8192_small/ckpt-21\n",
            "Time taken for 1 epoch: 631.0559570789337 secs\n",
            "\n",
            "Training loss 1.968275785446167, acc dcate,acc:0.5271323919296265 over epoch 64\n",
            "Validation acc over epoch 64: dcate,acc:0.5091152787208557\n",
            "Time taken for 1 epoch: 636.3760709762573 secs\n",
            "\n",
            "Training loss 1.9640083312988281, acc dcate,acc:0.5276919007301331 over epoch 65\n",
            "Validation acc over epoch 65: dcate,acc:0.5072602033615112\n",
            "Time taken for 1 epoch: 633.5125381946564 secs\n",
            "\n",
            "Training loss 1.9595969915390015, acc dcate,acc:0.5286017060279846 over epoch 66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJk6mNvfzEDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "3ddb6c36-c542-4aa6-ca69-5253ce926458"
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 39908\n",
            "drwxr-xr-x 1 root root     4096 Oct 10 08:20 .\n",
            "drwxr-xr-x 1 root root     4096 Oct  9 23:52 ..\n",
            "-rw-r--r-- 1 root root     2684 Oct  9 23:58 adc.json\n",
            "drwxr-xr-x 1 root root     4096 Oct  9 23:58 .config\n",
            "drwx------ 3 root root     4096 Oct 10 01:53 gdrive\n",
            "-rwxr-xr-x 1 root root 26683198 Oct  8 19:55 ngrok\n",
            "-rw-r--r-- 1 root root 13773305 Oct 10 08:20 ngrok-stable-linux-amd64.zip\n",
            "drwxr-xr-x 1 root root     4096 Aug 27 16:17 sample_data\n",
            "-rw-r--r-- 1 root root   299250 Oct  9 23:59 sp_10M.model\n",
            "-rw-r--r-- 1 root root    65266 Oct  9 23:59 sp_10M.vocab\n",
            "drwxr-xr-x 3 root root     4096 Oct 10 08:20 tmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbp-nlVeHn-0",
        "colab_type": "text"
      },
      "source": [
        "#### 타이틀 + 이미지: 20번 에포크시 VAL ACC: 0.40 대 (BATCH_SIZE = 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTy5Y5RkHSxD",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Epoch 1 Batch 100 Loss 3.2578\n",
        "Seen so far: 51200 samples\n",
        "Epoch 1 Batch 200 Loss 3.2198\n",
        "Seen so far: 102400 samples\n",
        "Epoch 1 Batch 300 Loss 3.2074\n",
        "Seen so far: 153600 samples\n",
        "Epoch 1 Batch 400 Loss 3.1938\n",
        "Seen so far: 204800 samples\n",
        "Epoch 1 Batch 500 Loss 3.1837\n",
        "Seen so far: 256000 samples\n",
        "Epoch 1 Batch 600 Loss 3.1762\n",
        "Seen so far: 307200 samples\n",
        "Epoch 1 Batch 700 Loss 3.1648\n",
        "Seen so far: 358400 samples\n",
        "Epoch 1 Batch 800 Loss 3.1218\n",
        "Seen so far: 409600 samples\n",
        "Epoch 1 Batch 900 Loss 3.0571\n",
        "Seen so far: 460800 samples\n",
        "Epoch 1 Batch 1000 Loss 3.0049\n",
        "Seen so far: 512000 samples\n",
        "Epoch 1 Batch 1100 Loss 2.9584\n",
        "Seen so far: 563200 samples\n",
        "Epoch 1 Batch 1200 Loss 2.9215\n",
        "Seen so far: 614400 samples\n",
        "Epoch 1 Batch 1300 Loss 2.8882\n",
        "Seen so far: 665600 samples\n",
        "Epoch 1 Batch 1400 Loss 2.8587\n",
        "Seen so far: 716800 samples\n",
        "Epoch 1 Batch 1500 Loss 2.8334\n",
        "Seen so far: 768000 samples\n",
        "Epoch 1 Batch 1600 Loss 2.8141\n",
        "Seen so far: 819200 samples\n",
        "Epoch 1 Batch 1700 Loss 2.8004\n",
        "Seen so far: 870400 samples\n",
        "Epoch 1 Batch 1800 Loss 2.7894\n",
        "Seen so far: 921600 samples\n",
        "Epoch 1 Batch 1900 Loss 2.7807\n",
        "Seen so far: 972800 samples\n",
        "Epoch 1 Batch 2000 Loss 2.7811\n",
        "Seen so far: 1024000 samples\n",
        "Epoch 1 Batch 2100 Loss 2.7874\n",
        "Seen so far: 1075200 samples\n",
        "Epoch 1 Batch 2200 Loss 2.7938\n",
        "Seen so far: 1126400 samples\n",
        "Epoch 1 Batch 2300 Loss 2.8017\n",
        "Seen so far: 1177600 samples\n",
        "Epoch 1 Batch 2400 Loss 2.8161\n",
        "Seen so far: 1228800 samples\n",
        "Epoch 1 Batch 2500 Loss 2.8301\n",
        "Seen so far: 1280000 samples\n",
        "Epoch 1 Batch 2600 Loss 2.8432\n",
        "Seen so far: 1331200 samples\n",
        "Epoch 1 Batch 2700 Loss 2.8544\n",
        "Seen so far: 1382400 samples\n",
        "Epoch 1 Batch 2800 Loss 2.8575\n",
        "Seen so far: 1433600 samples\n",
        "Epoch 1 Batch 2900 Loss 2.8583\n",
        "Seen so far: 1484800 samples\n",
        "Epoch 1 Batch 3000 Loss 2.8563\n",
        "Seen so far: 1536000 samples\n",
        "Epoch 1 Batch 3100 Loss 2.8459\n",
        "Seen so far: 1587200 samples\n",
        "Epoch 1 Batch 3200 Loss 2.8355\n",
        "Seen so far: 1638400 samples\n",
        "Epoch 1 Batch 3300 Loss 2.8253\n",
        "Seen so far: 1689600 samples\n",
        "Epoch 1 Batch 3400 Loss 2.8153\n",
        "Seen so far: 1740800 samples\n",
        "Epoch 1 Batch 3500 Loss 2.8058\n",
        "Seen so far: 1792000 samples\n",
        "Epoch 1 Batch 3600 Loss 2.7973\n",
        "Seen so far: 1843200 samples\n",
        "Epoch 1 Batch 3700 Loss 2.7891\n",
        "Seen so far: 1894400 samples\n",
        "Epoch 1 Batch 3800 Loss 2.7818\n",
        "Seen so far: 1945600 samples\n",
        "Epoch 1 Batch 3900 Loss 2.7776\n",
        "Seen so far: 1996800 samples\n",
        "Epoch 1 Batch 4000 Loss 2.7742\n",
        "Seen so far: 2048000 samples\n",
        "Epoch 1 Batch 4100 Loss 2.7701\n",
        "Seen so far: 2099200 samples\n",
        "Epoch 1 Batch 4200 Loss 2.7663\n",
        "Seen so far: 2150400 samples\n",
        "Training loss 2.764740228652954, acc dcate,acc:0.41291549801826477 over epoch 1\n",
        "Validation acc over epoch 1: dcate,acc:0.4040367305278778\n",
        "Time taken for 1 epoch: 1423.2469387054443 secs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ypivbzpt8d4",
        "colab_type": "text"
      },
      "source": [
        "#### 타이틀 (온리): 20번 에포크시 VAL ACC: 0.408 대 (BATCH_SIZE = 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJGa3SaHuDJq",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Epoch 1 Batch 100 Loss 8.8723\n",
        "Seen so far: 51200 samples\n",
        "Epoch 1 Batch 200 Loss 8.6593\n",
        "Seen so far: 102400 samples\n",
        "Epoch 1 Batch 300 Loss 8.2883\n",
        "Seen so far: 153600 samples\n",
        "Epoch 1 Batch 400 Loss 8.0273\n",
        "Seen so far: 204800 samples\n",
        "Epoch 1 Batch 500 Loss 7.8373\n",
        "Seen so far: 256000 samples\n",
        "Epoch 1 Batch 600 Loss 7.6896\n",
        "Seen so far: 307200 samples\n",
        "Epoch 1 Batch 700 Loss 7.5618\n",
        "Seen so far: 358400 samples\n",
        "Epoch 1 Batch 800 Loss 7.4204\n",
        "Seen so far: 409600 samples\n",
        "Epoch 1 Batch 900 Loss 7.2465\n",
        "Seen so far: 460800 samples\n",
        "Epoch 1 Batch 1000 Loss 7.0694\n",
        "Seen so far: 512000 samples\n",
        "Epoch 1 Batch 1100 Loss 6.8956\n",
        "Seen so far: 563200 samples\n",
        "Epoch 1 Batch 1200 Loss 6.7307\n",
        "Seen so far: 614400 samples\n",
        "Epoch 1 Batch 1300 Loss 6.5768\n",
        "Seen so far: 665600 samples\n",
        "Epoch 1 Batch 1400 Loss 6.4311\n",
        "Seen so far: 716800 samples\n",
        "Epoch 1 Batch 1500 Loss 6.2970\n",
        "Seen so far: 768000 samples\n",
        "Epoch 1 Batch 1600 Loss 6.1824\n",
        "Seen so far: 819200 samples\n",
        "Epoch 1 Batch 1700 Loss 6.0809\n",
        "Seen so far: 870400 samples\n",
        "Epoch 1 Batch 1800 Loss 5.9828\n",
        "Seen so far: 921600 samples\n",
        "Epoch 1 Batch 1900 Loss 5.8891\n",
        "Seen so far: 972800 samples\n",
        "Epoch 1 Batch 2000 Loss 5.8209\n",
        "Seen so far: 1024000 samples\n",
        "Epoch 1 Batch 2100 Loss 5.7708\n",
        "Seen so far: 1075200 samples\n",
        "Epoch 1 Batch 2200 Loss 5.7220\n",
        "Seen so far: 1126400 samples\n",
        "Epoch 1 Batch 2300 Loss 5.6782\n",
        "Seen so far: 1177600 samples\n",
        "Epoch 1 Batch 2400 Loss 5.6458\n",
        "Seen so far: 1228800 samples\n",
        "Epoch 1 Batch 2500 Loss 5.6116\n",
        "Seen so far: 1280000 samples\n",
        "Epoch 1 Batch 2600 Loss 5.5765\n",
        "Seen so far: 1331200 samples\n",
        "Epoch 1 Batch 2700 Loss 5.5407\n",
        "Seen so far: 1382400 samples\n",
        "Epoch 1 Batch 2800 Loss 5.5012\n",
        "Seen so far: 1433600 samples\n",
        "Epoch 1 Batch 2900 Loss 5.4601\n",
        "Seen so far: 1484800 samples\n",
        "Epoch 1 Batch 3000 Loss 5.4176\n",
        "Seen so far: 1536000 samples\n",
        "Epoch 1 Batch 3100 Loss 5.3659\n",
        "Seen so far: 1587200 samples\n",
        "Epoch 1 Batch 3200 Loss 5.3148\n",
        "Seen so far: 1638400 samples\n",
        "Epoch 1 Batch 3300 Loss 5.2646\n",
        "Seen so far: 1689600 samples\n",
        "Epoch 1 Batch 3400 Loss 5.2159\n",
        "Seen so far: 1740800 samples\n",
        "Epoch 1 Batch 3500 Loss 5.1688\n",
        "Seen so far: 1792000 samples\n",
        "Epoch 1 Batch 3600 Loss 5.1244\n",
        "Seen so far: 1843200 samples\n",
        "Epoch 1 Batch 3700 Loss 5.0820\n",
        "Seen so far: 1894400 samples\n",
        "Epoch 1 Batch 3800 Loss 5.0432\n",
        "Seen so far: 1945600 samples\n",
        "Epoch 1 Batch 3900 Loss 5.0094\n",
        "Seen so far: 1996800 samples\n",
        "Epoch 1 Batch 4000 Loss 4.9751\n",
        "Seen so far: 2048000 samples\n",
        "Epoch 1 Batch 4100 Loss 4.9400\n",
        "Seen so far: 2099200 samples\n",
        "Epoch 1 Batch 4200 Loss 4.9053\n",
        "Seen so far: 2150400 samples\n",
        "Training loss 4.8917460441589355, acc dcate,acc:0.18037939071655273 over epoch 1\n",
        "Validation acc over epoch 1: dcate,acc:0.18056800961494446\n",
        "Time taken for 1 epoch: 1315.7310771942139 secs\n",
        "\n",
        "...\n",
        "\n",
        "Epoch 21 Batch 100 Loss 3.2581\n",
        "Seen so far: 51200 samples\n",
        "Epoch 21 Batch 200 Loss 3.2261\n",
        "Seen so far: 102400 samples\n",
        "Epoch 21 Batch 300 Loss 3.2063\n",
        "Seen so far: 153600 samples\n",
        "Epoch 21 Batch 400 Loss 3.1936\n",
        "Seen so far: 204800 samples\n",
        "Epoch 21 Batch 500 Loss 3.1797\n",
        "Seen so far: 256000 samples\n",
        "Epoch 21 Batch 600 Loss 3.1741\n",
        "Seen so far: 307200 samples\n",
        "Epoch 21 Batch 700 Loss 3.1669\n",
        "Seen so far: 358400 samples\n",
        "Epoch 21 Batch 800 Loss 3.1209\n",
        "Seen so far: 409600 samples\n",
        "Epoch 21 Batch 900 Loss 3.0563\n",
        "Seen so far: 460800 samples\n",
        "Epoch 21 Batch 1000 Loss 3.0044\n",
        "Seen so far: 512000 samples\n",
        "Epoch 21 Batch 1100 Loss 2.9595\n",
        "Seen so far: 563200 samples\n",
        "Epoch 21 Batch 1200 Loss 2.9212\n",
        "Seen so far: 614400 samples\n",
        "Epoch 21 Batch 1300 Loss 2.8881\n",
        "Seen so far: 665600 samples\n",
        "Epoch 21 Batch 1400 Loss 2.8581\n",
        "Seen so far: 716800 samples\n",
        "Epoch 21 Batch 1500 Loss 2.8321\n",
        "Seen so far: 768000 samples\n",
        "Epoch 21 Batch 1600 Loss 2.8130\n",
        "Seen so far: 819200 samples\n",
        "Epoch 21 Batch 1700 Loss 2.7992\n",
        "Seen so far: 870400 samples\n",
        "Epoch 21 Batch 1800 Loss 2.7876\n",
        "Seen so far: 921600 samples\n",
        "Epoch 21 Batch 1900 Loss 2.7797\n",
        "Seen so far: 972800 samples\n",
        "Epoch 21 Batch 2000 Loss 2.7797\n",
        "Seen so far: 1024000 samples\n",
        "Epoch 21 Batch 2100 Loss 2.7857\n",
        "Seen so far: 1075200 samples\n",
        "Epoch 21 Batch 2200 Loss 2.7918\n",
        "Seen so far: 1126400 samples\n",
        "Epoch 21 Batch 2300 Loss 2.7991\n",
        "Seen so far: 1177600 samples\n",
        "Epoch 21 Batch 2400 Loss 2.8130\n",
        "Seen so far: 1228800 samples\n",
        "Epoch 21 Batch 2500 Loss 2.8265\n",
        "Seen so far: 1280000 samples\n",
        "Epoch 21 Batch 2600 Loss 2.8403\n",
        "Seen so far: 1331200 samples\n",
        "Epoch 21 Batch 2700 Loss 2.8512\n",
        "Seen so far: 1382400 samples\n",
        "Epoch 21 Batch 2800 Loss 2.8544\n",
        "Seen so far: 1433600 samples\n",
        "Epoch 21 Batch 2900 Loss 2.8542\n",
        "Seen so far: 1484800 samples\n",
        "Epoch 21 Batch 3000 Loss 2.8528\n",
        "Seen so far: 1536000 samples\n",
        "Epoch 21 Batch 3100 Loss 2.8427\n",
        "Seen so far: 1587200 samples\n",
        "Epoch 21 Batch 3200 Loss 2.8316\n",
        "Seen so far: 1638400 samples\n",
        "Epoch 21 Batch 3300 Loss 2.8211\n",
        "Seen so far: 1689600 samples\n",
        "Epoch 21 Batch 3400 Loss 2.8115\n",
        "Seen so far: 1740800 samples\n",
        "Epoch 21 Batch 3500 Loss 2.8020\n",
        "Seen so far: 1792000 samples\n",
        "Epoch 21 Batch 3600 Loss 2.7932\n",
        "Seen so far: 1843200 samples\n",
        "Epoch 21 Batch 3700 Loss 2.7848\n",
        "Seen so far: 1894400 samples\n",
        "Epoch 21 Batch 3800 Loss 2.7774\n",
        "Seen so far: 1945600 samples\n",
        "Epoch 21 Batch 3900 Loss 2.7725\n",
        "Seen so far: 1996800 samples\n",
        "Epoch 21 Batch 4000 Loss 2.7689\n",
        "Seen so far: 2048000 samples\n",
        "Epoch 21 Batch 4100 Loss 2.7647\n",
        "Seen so far: 2099200 samples\n",
        "Epoch 21 Batch 4200 Loss 2.7609\n",
        "Seen so far: 2150400 samples\n",
        "Training loss 2.7592458724975586, acc dcate,acc:0.4174620509147644 over epoch 21\n",
        "Validation acc over epoch 21: dcate,acc:0.40857332944869995\n",
        "Saving checkpoint for epoch 21 at gdrive/My Drive/data/checkpoints/train_prod_clf_title_only/ckpt-7\n",
        "Time taken for 1 epoch: 1236.48423910141 secs\n",
        " \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD8zbTE9HKo-",
        "colab_type": "text"
      },
      "source": [
        "## 참고: 배송 2.0 딜의 타이틀로만 구성했을 때 결과"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l25XQ_snXiA",
        "colab_type": "text"
      },
      "source": [
        "#### 학습 로그, BATCH_SIZE=1,024\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At5GqRjlnmuO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Epoch 1 Batch 100 Loss 23.2969\n",
        "Seen so far: 102400 samples\n",
        "Epoch 1 Batch 200 Loss 21.7064\n",
        "Seen so far: 204800 samples\n",
        "Epoch 1 Batch 300 Loss 20.1441\n",
        "Seen so far: 307200 samples\n",
        "Epoch 1 Batch 400 Loss 18.6555\n",
        "Seen so far: 409600 samples\n",
        "Epoch 1 Batch 500 Loss 17.3532\n",
        "Seen so far: 512000 samples\n",
        "Epoch 1 Batch 600 Loss 16.2529\n",
        "Seen so far: 614400 samples\n",
        "Epoch 1 Batch 700 Loss 15.3040\n",
        "Seen so far: 716800 samples\n",
        "Epoch 1 Batch 800 Loss 14.4827\n",
        "Seen so far: 819200 samples\n",
        "Training loss 13.919532775878906, acc dcate,acc:0.1611873060464859\tscate,acc:0.21777121722698212\tmcate,acc:0.36421775817871094\tlcate,acc:0.5731943845748901 over epoch 1\n",
        "Validation acc over epoch 1: dcate,acc:0.350193589925766\tscate,acc:0.45061057806015015\tmcate,acc:0.6368991732597351\tlcate,acc:0.7929887771606445\n",
        "Time taken for 1 epoch: 439.31024861335754 secs\n",
        "\n",
        "Epoch 2 Batch 100 Loss 7.5944\n",
        "Seen so far: 102400 samples\n",
        "Epoch 2 Batch 200 Loss 7.3805\n",
        "Seen so far: 204800 samples\n",
        "Epoch 2 Batch 300 Loss 7.1792\n",
        "Seen so far: 307200 samples\n",
        "Epoch 2 Batch 400 Loss 7.0096\n",
        "Seen so far: 409600 samples\n",
        "Epoch 2 Batch 500 Loss 6.8594\n",
        "Seen so far: 512000 samples\n",
        "Epoch 2 Batch 600 Loss 6.7293\n",
        "Seen so far: 614400 samples\n",
        "Epoch 2 Batch 700 Loss 6.6036\n",
        "Seen so far: 716800 samples\n",
        "Epoch 2 Batch 800 Loss 6.4905\n",
        "Seen so far: 819200 samples\n",
        "Training loss 6.409360885620117, acc dcate,acc:0.4262094795703888\tscate,acc:0.5222941040992737\tmcate,acc:0.6740705966949463\tlcate,acc:0.7965869307518005 over epoch 2\n",
        "Validation acc over epoch 2: dcate,acc:0.4974597990512848\tscate,acc:0.5961183905601501\tmcate,acc:0.7234352231025696\tlcate,acc:0.8268563151359558\n",
        "Time taken for 1 epoch: 333.6743543148041 secs\n",
        "\n",
        "Epoch 3 Batch 100 Loss 5.4100\n",
        "Seen so far: 102400 samples\n",
        "Epoch 3 Batch 200 Loss 5.3538\n",
        "Seen so far: 204800 samples\n",
        "Epoch 3 Batch 300 Loss 5.2882\n",
        "Seen so far: 307200 samples\n",
        "Epoch 3 Batch 400 Loss 5.2371\n",
        "Seen so far: 409600 samples\n",
        "Epoch 3 Batch 500 Loss 5.1870\n",
        "Seen so far: 512000 samples\n",
        "Epoch 3 Batch 600 Loss 5.1496\n",
        "Seen so far: 614400 samples\n",
        "Epoch 3 Batch 700 Loss 5.1072\n",
        "Seen so far: 716800 samples\n",
        "Epoch 3 Batch 800 Loss 5.0690\n",
        "Seen so far: 819200 samples\n",
        "Training loss 5.0410661697387695, acc dcate,acc:0.5126997828483582\tscate,acc:0.6068646311759949\tmcate,acc:0.7247795462608337\tlcate,acc:0.8239762783050537 over epoch 3\n",
        "Validation acc over epoch 3: dcate,acc:0.5479518175125122\tscate,acc:0.637955904006958\tmcate,acc:0.748144268989563\tlcate,acc:0.8408632874488831\n",
        "Saving checkpoint for epoch 3 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-1\n",
        "Time taken for 1 epoch: 335.8052759170532 secs\n",
        "\n",
        "Epoch 4 Batch 100 Loss 4.6416\n",
        "Seen so far: 102400 samples\n",
        "Epoch 4 Batch 200 Loss 4.6158\n",
        "Seen so far: 204800 samples\n",
        "Epoch 4 Batch 300 Loss 4.5857\n",
        "Seen so far: 307200 samples\n",
        "Epoch 4 Batch 400 Loss 4.5627\n",
        "Seen so far: 409600 samples\n",
        "Epoch 4 Batch 500 Loss 4.5416\n",
        "Seen so far: 512000 samples\n",
        "Epoch 4 Batch 600 Loss 4.5276\n",
        "Seen so far: 614400 samples\n",
        "Epoch 4 Batch 700 Loss 4.5071\n",
        "Seen so far: 716800 samples\n",
        "Epoch 4 Batch 800 Loss 4.4895\n",
        "Seen so far: 819200 samples\n",
        "Training loss 4.474783897399902, acc dcate,acc:0.5520581007003784\tscate,acc:0.6408641338348389\tmcate,acc:0.7497997879981995\tlcate,acc:0.8410171866416931 over epoch 4\n",
        "Validation acc over epoch 4: dcate,acc:0.5716699361801147\tscate,acc:0.660651683807373\tmcate,acc:0.7638351321220398\tlcate,acc:0.8523700833320618\n",
        "Time taken for 1 epoch: 325.24789571762085 secs\n",
        "\n",
        "Epoch 5 Batch 100 Loss 4.2482\n",
        "Seen so far: 102400 samples\n",
        "Epoch 5 Batch 200 Loss 4.2358\n",
        "Seen so far: 204800 samples\n",
        "Epoch 5 Batch 300 Loss 4.2155\n",
        "Seen so far: 307200 samples\n",
        "Epoch 5 Batch 400 Loss 4.2015\n",
        "Seen so far: 409600 samples\n",
        "Epoch 5 Batch 500 Loss 4.1909\n",
        "Seen so far: 512000 samples\n",
        "Epoch 5 Batch 600 Loss 4.1841\n",
        "Seen so far: 614400 samples\n",
        "Epoch 5 Batch 700 Loss 4.1690\n",
        "Seen so far: 716800 samples\n",
        "Epoch 5 Batch 800 Loss 4.1556\n",
        "Seen so far: 819200 samples\n",
        "Training loss 4.143682956695557, acc dcate,acc:0.5748549699783325\tscate,acc:0.6619903445243835\tmcate,acc:0.7672155499458313\tlcate,acc:0.8533721566200256 over epoch 5\n",
        "Validation acc over epoch 5: dcate,acc:0.5871317386627197\tscate,acc:0.6730835437774658\tmcate,acc:0.7732484936714172\tlcate,acc:0.8590399622917175\n",
        "Time taken for 1 epoch: 335.0390079021454 secs\n",
        "\n",
        "Epoch 6 Batch 100 Loss 3.9479\n",
        "Seen so far: 102400 samples\n",
        "Epoch 6 Batch 200 Loss 3.9304\n",
        "Seen so far: 204800 samples\n",
        "Epoch 6 Batch 300 Loss 3.9068\n",
        "Seen so far: 307200 samples\n",
        "Epoch 6 Batch 400 Loss 3.8910\n",
        "Seen so far: 409600 samples\n",
        "Epoch 6 Batch 500 Loss 3.8747\n",
        "Seen so far: 512000 samples\n",
        "Epoch 6 Batch 600 Loss 3.8649\n",
        "Seen so far: 614400 samples\n",
        "Epoch 6 Batch 700 Loss 3.8493\n",
        "Seen so far: 716800 samples\n",
        "Epoch 6 Batch 800 Loss 3.8366\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.825269937515259, acc dcate,acc:0.5975995063781738\tscate,acc:0.6828941106796265\tmcate,acc:0.7842174768447876\tlcate,acc:0.8655735850334167 over epoch 6\n",
        "Validation acc over epoch 6: dcate,acc:0.604065477848053\tscate,acc:0.6875945329666138\tmcate,acc:0.7855543494224548\tlcate,acc:0.8666032552719116\n",
        "Saving checkpoint for epoch 6 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-2\n",
        "Time taken for 1 epoch: 325.6901412010193 secs\n",
        "\n",
        "Epoch 7 Batch 100 Loss 3.6518\n",
        "Seen so far: 102400 samples\n",
        "Epoch 7 Batch 200 Loss 3.6455\n",
        "Seen so far: 204800 samples\n",
        "Epoch 7 Batch 300 Loss 3.6294\n",
        "Seen so far: 307200 samples\n",
        "Epoch 7 Batch 400 Loss 3.6197\n",
        "Seen so far: 409600 samples\n",
        "Epoch 7 Batch 500 Loss 3.6075\n",
        "Seen so far: 512000 samples\n",
        "Epoch 7 Batch 600 Loss 3.6010\n",
        "Seen so far: 614400 samples\n",
        "Epoch 7 Batch 700 Loss 3.5930\n",
        "Seen so far: 716800 samples\n",
        "Epoch 7 Batch 800 Loss 3.5844\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.5761101245880127, acc dcate,acc:0.614652693271637\tscate,acc:0.6986381411552429\tmcate,acc:0.7984544038772583\tlcate,acc:0.8764270544052124 over epoch 7\n",
        "Validation acc over epoch 7: dcate,acc:0.6118665337562561\tscate,acc:0.6939235329627991\tmcate,acc:0.7920494675636292\tlcate,acc:0.870543897151947\n",
        "Time taken for 1 epoch: 335.8001775741577 secs\n",
        "\n",
        "Epoch 8 Batch 100 Loss 3.4407\n",
        "Seen so far: 102400 samples\n",
        "Epoch 8 Batch 200 Loss 3.4454\n",
        "Seen so far: 204800 samples\n",
        "Epoch 8 Batch 300 Loss 3.4270\n",
        "Seen so far: 307200 samples\n",
        "Epoch 8 Batch 400 Loss 3.4190\n",
        "Seen so far: 409600 samples\n",
        "Epoch 8 Batch 500 Loss 3.4116\n",
        "Seen so far: 512000 samples\n",
        "Epoch 8 Batch 600 Loss 3.4087\n",
        "Seen so far: 614400 samples\n",
        "Epoch 8 Batch 700 Loss 3.4013\n",
        "Seen so far: 716800 samples\n",
        "Epoch 8 Batch 800 Loss 3.3959\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.390206813812256, acc dcate,acc:0.6279208064079285\tscate,acc:0.7105492949485779\tmcate,acc:0.808826208114624\tlcate,acc:0.8832996487617493 over epoch 8\n",
        "Validation acc over epoch 8: dcate,acc:0.6196074485778809\tscate,acc:0.699837327003479\tmcate,acc:0.7988768219947815\tlcate,acc:0.874710738658905\n",
        "Time taken for 1 epoch: 326.1968834400177 secs\n",
        "\n",
        "Epoch 9 Batch 100 Loss 3.2849\n",
        "Seen so far: 102400 samples\n",
        "Epoch 9 Batch 200 Loss 3.2870\n",
        "Seen so far: 204800 samples\n",
        "Epoch 9 Batch 300 Loss 3.2736\n",
        "Seen so far: 307200 samples\n",
        "Epoch 9 Batch 400 Loss 3.2670\n",
        "Seen so far: 409600 samples\n",
        "Epoch 9 Batch 500 Loss 3.2617\n",
        "Seen so far: 512000 samples\n",
        "Epoch 9 Batch 600 Loss 3.2596\n",
        "Seen so far: 614400 samples\n",
        "Epoch 9 Batch 700 Loss 3.2543\n",
        "Seen so far: 716800 samples\n",
        "Epoch 9 Batch 800 Loss 3.2512\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.245605707168579, acc dcate,acc:0.6382614374160767\tscate,acc:0.7202949523925781\tmcate,acc:0.8175529837608337\tlcate,acc:0.8893436789512634 over epoch 9\n",
        "Validation acc over epoch 9: dcate,acc:0.6257045269012451\tscate,acc:0.7059916853904724\tmcate,acc:0.8036679625511169\tlcate,acc:0.877806544303894\n",
        "Saving checkpoint for epoch 9 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-3\n",
        "Time taken for 1 epoch: 336.3138952255249 secs\n",
        "\n",
        "Epoch 10 Batch 100 Loss 3.1707\n",
        "Seen so far: 102400 samples\n",
        "Epoch 10 Batch 200 Loss 3.1629\n",
        "Seen so far: 204800 samples\n",
        "Epoch 10 Batch 300 Loss 3.1538\n",
        "Seen so far: 307200 samples\n",
        "Epoch 10 Batch 400 Loss 3.1482\n",
        "Seen so far: 409600 samples\n",
        "Epoch 10 Batch 500 Loss 3.1449\n",
        "Seen so far: 512000 samples\n",
        "Epoch 10 Batch 600 Loss 3.1440\n",
        "Seen so far: 614400 samples\n",
        "Epoch 10 Batch 700 Loss 3.1399\n",
        "Seen so far: 716800 samples\n",
        "Epoch 10 Batch 800 Loss 3.1388\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.1341264247894287, acc dcate,acc:0.645902693271637\tscate,acc:0.7276803255081177\tmcate,acc:0.823177695274353\tlcate,acc:0.8935224413871765 over epoch 10\n",
        "Validation acc over epoch 10: dcate,acc:0.6301634907722473\tscate,acc:0.709465503692627\tmcate,acc:0.806047797203064\tlcate,acc:0.8791812062263489\n",
        "Time taken for 1 epoch: 325.63170981407166 secs\n",
        "\n",
        "Epoch 11 Batch 100 Loss 3.0665\n",
        "Seen so far: 102400 samples\n",
        "Epoch 11 Batch 200 Loss 3.0603\n",
        "Seen so far: 204800 samples\n",
        "Epoch 11 Batch 300 Loss 3.0508\n",
        "Seen so far: 307200 samples\n",
        "Epoch 11 Batch 400 Loss 3.0450\n",
        "Seen so far: 409600 samples\n",
        "Epoch 11 Batch 500 Loss 3.0431\n",
        "Seen so far: 512000 samples\n",
        "Epoch 11 Batch 600 Loss 3.0427\n",
        "Seen so far: 614400 samples\n",
        "Epoch 11 Batch 700 Loss 3.0393\n",
        "Seen so far: 716800 samples\n",
        "Epoch 11 Batch 800 Loss 3.0380\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.033891439437866, acc dcate,acc:0.6532235741615295\tscate,acc:0.7346063256263733\tmcate,acc:0.8291382789611816\tlcate,acc:0.8975031971931458 over epoch 11\n",
        "Validation acc over epoch 11: dcate,acc:0.6329814791679382\tscate,acc:0.7128562331199646\tmcate,acc:0.8071933388710022\tlcate,acc:0.8806130886077881\n",
        "Time taken for 1 epoch: 325.49516248703003 secs\n",
        "\n",
        "Epoch 12 Batch 100 Loss 2.9791\n",
        "Seen so far: 102400 samples\n",
        "Epoch 12 Batch 200 Loss 2.9742\n",
        "Seen so far: 204800 samples\n",
        "Epoch 12 Batch 300 Loss 2.9663\n",
        "Seen so far: 307200 samples\n",
        "Epoch 12 Batch 400 Loss 2.9605\n",
        "Seen so far: 409600 samples\n",
        "Epoch 12 Batch 500 Loss 2.9595\n",
        "Seen so far: 512000 samples\n",
        "Epoch 12 Batch 600 Loss 2.9605\n",
        "Seen so far: 614400 samples\n",
        "Epoch 12 Batch 700 Loss 2.9565\n",
        "Seen so far: 716800 samples\n",
        "Epoch 12 Batch 800 Loss 2.9562\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.953066110610962, acc dcate,acc:0.6590818166732788\tscate,acc:0.7402032613754272\tmcate,acc:0.8338998556137085\tlcate,acc:0.9009333848953247 over epoch 12\n",
        "Validation acc over epoch 12: dcate,acc:0.636483907699585\tscate,acc:0.7151387333869934\tmcate,acc:0.8100915551185608\tlcate,acc:0.8829872012138367\n",
        "Saving checkpoint for epoch 12 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-4\n",
        "Time taken for 1 epoch: 326.1110873222351 secs\n",
        "\n",
        "Epoch 13 Batch 100 Loss 2.8943\n",
        "Seen so far: 102400 samples\n",
        "Epoch 13 Batch 200 Loss 2.8936\n",
        "Seen so far: 204800 samples\n",
        "Epoch 13 Batch 300 Loss 2.8888\n",
        "Seen so far: 307200 samples\n",
        "Epoch 13 Batch 400 Loss 2.8839\n",
        "Seen so far: 409600 samples\n",
        "Epoch 13 Batch 500 Loss 2.8815\n",
        "Seen so far: 512000 samples\n",
        "Epoch 13 Batch 600 Loss 2.8828\n",
        "Seen so far: 614400 samples\n",
        "Epoch 13 Batch 700 Loss 2.8802\n",
        "Seen so far: 716800 samples\n",
        "Epoch 13 Batch 800 Loss 2.8799\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.877784490585327, acc dcate,acc:0.6643672585487366\tscate,acc:0.7454441785812378\tmcate,acc:0.8382031917572021\tlcate,acc:0.904041051864624 over epoch 13\n",
        "Validation acc over epoch 13: dcate,acc:0.6379874348640442\tscate,acc:0.71627277135849\tmcate,acc:0.8112657070159912\tlcate,acc:0.8835828900337219\n",
        "Time taken for 1 epoch: 325.565217256546 secs\n",
        "\n",
        "Epoch 14 Batch 100 Loss 2.8366\n",
        "Seen so far: 102400 samples\n",
        "Epoch 14 Batch 200 Loss 2.8317\n",
        "Seen so far: 204800 samples\n",
        "Epoch 14 Batch 300 Loss 2.8234\n",
        "Seen so far: 307200 samples\n",
        "Epoch 14 Batch 400 Loss 2.8199\n",
        "Seen so far: 409600 samples\n",
        "Epoch 14 Batch 500 Loss 2.8181\n",
        "Seen so far: 512000 samples\n",
        "Epoch 14 Batch 600 Loss 2.8195\n",
        "Seen so far: 614400 samples\n",
        "Epoch 14 Batch 700 Loss 2.8179\n",
        "Seen so far: 716800 samples\n",
        "Epoch 14 Batch 800 Loss 2.8202\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.8178536891937256, acc dcate,acc:0.6687517762184143\tscate,acc:0.7494861483573914\tmcate,acc:0.8409715890884399\tlcate,acc:0.9060553312301636 over epoch 14\n",
        "Validation acc over epoch 14: dcate,acc:0.6415843963623047\tscate,acc:0.7201848030090332\tmcate,acc:0.8130154609680176\tlcate,acc:0.8845279216766357\n",
        "Time taken for 1 epoch: 325.72965908050537 secs\n",
        "\n",
        "Epoch 15 Batch 100 Loss 2.7819\n",
        "Seen so far: 102400 samples\n",
        "Epoch 15 Batch 200 Loss 2.7718\n",
        "Seen so far: 204800 samples\n",
        "Epoch 15 Batch 300 Loss 2.7635\n",
        "Seen so far: 307200 samples\n",
        "Epoch 15 Batch 400 Loss 2.7613\n",
        "Seen so far: 409600 samples\n",
        "Epoch 15 Batch 500 Loss 2.7608\n",
        "Seen so far: 512000 samples\n",
        "Epoch 15 Batch 600 Loss 2.7614\n",
        "Seen so far: 614400 samples\n",
        "Epoch 15 Batch 700 Loss 2.7589\n",
        "Seen so far: 716800 samples\n",
        "Epoch 15 Batch 800 Loss 2.7592\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.7584099769592285, acc dcate,acc:0.673072874546051\tscate,acc:0.7530487179756165\tmcate,acc:0.844663143157959\tlcate,acc:0.9085401296615601 over epoch 15\n",
        "Validation acc over epoch 15: dcate,acc:0.642357587814331\tscate,acc:0.7201017141342163\tmcate,acc:0.8137428760528564\tlcate,acc:0.8847570419311523\n",
        "Saving checkpoint for epoch 15 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-5\n",
        "Time taken for 1 epoch: 325.56688928604126 secs\n",
        "\n",
        "Epoch 16 Batch 100 Loss 2.7261\n",
        "Seen so far: 102400 samples\n",
        "Epoch 16 Batch 200 Loss 2.7187\n",
        "Seen so far: 204800 samples\n",
        "Epoch 16 Batch 300 Loss 2.7128\n",
        "Seen so far: 307200 samples\n",
        "Epoch 16 Batch 400 Loss 2.7115\n",
        "Seen so far: 409600 samples\n",
        "Epoch 16 Batch 500 Loss 2.7109\n",
        "Seen so far: 512000 samples\n",
        "Epoch 16 Batch 600 Loss 2.7147\n",
        "Seen so far: 614400 samples\n",
        "Epoch 16 Batch 700 Loss 2.7115\n",
        "Seen so far: 716800 samples\n",
        "Epoch 16 Batch 800 Loss 2.7121\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.7108566761016846, acc dcate,acc:0.6766054034233093\tscate,acc:0.756614625453949\tmcate,acc:0.8476240038871765\tlcate,acc:0.9104965925216675 over epoch 16\n",
        "Validation acc over epoch 16: dcate,acc:0.6432310938835144\tscate,acc:0.7211269736289978\tmcate,acc:0.814644992351532\tlcate,acc:0.8848143219947815\n",
        "Time taken for 1 epoch: 334.76745343208313 secs\n",
        "\n",
        "Epoch 17 Batch 100 Loss 2.6695\n",
        "Seen so far: 102400 samples\n",
        "Epoch 17 Batch 200 Loss 2.6664\n",
        "Seen so far: 204800 samples\n",
        "Epoch 17 Batch 300 Loss 2.6629\n",
        "Seen so far: 307200 samples\n",
        "Epoch 17 Batch 400 Loss 2.6598\n",
        "Seen so far: 409600 samples\n",
        "Epoch 17 Batch 500 Loss 2.6608\n",
        "Seen so far: 512000 samples\n",
        "Epoch 17 Batch 600 Loss 2.6628\n",
        "Seen so far: 614400 samples\n",
        "Epoch 17 Batch 700 Loss 2.6598\n",
        "Seen so far: 716800 samples\n",
        "Epoch 17 Batch 800 Loss 2.6617\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.6603641510009766, acc dcate,acc:0.6806095838546753\tscate,acc:0.7602828145027161\tmcate,acc:0.8503623604774475\tlcate,acc:0.9124675393104553 over epoch 17\n",
        "Validation acc over epoch 17: dcate,acc:0.645218551158905\tscate,acc:0.7229512333869934\tmcate,acc:0.8160597085952759\tlcate,acc:0.8860830068588257\n",
        "Time taken for 1 epoch: 325.09432458877563 secs\n",
        "\n",
        "Epoch 18 Batch 100 Loss 2.6304\n",
        "Seen so far: 102400 samples\n",
        "Epoch 18 Batch 200 Loss 2.6282\n",
        "Seen so far: 204800 samples\n",
        "Epoch 18 Batch 300 Loss 2.6199\n",
        "Seen so far: 307200 samples\n",
        "Epoch 18 Batch 400 Loss 2.6172\n",
        "Seen so far: 409600 samples\n",
        "Epoch 18 Batch 500 Loss 2.6178\n",
        "Seen so far: 512000 samples\n",
        "Epoch 18 Batch 600 Loss 2.6210\n",
        "Seen so far: 614400 samples\n",
        "Epoch 18 Batch 700 Loss 2.6197\n",
        "Seen so far: 716800 samples\n",
        "Epoch 18 Batch 800 Loss 2.6210\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.6198177337646484, acc dcate,acc:0.6833835244178772\tscate,acc:0.7631001472473145\tmcate,acc:0.8529072403907776\tlcate,acc:0.9141648411750793 over epoch 18\n",
        "Validation acc over epoch 18: dcate,acc:0.6455908417701721\tscate,acc:0.7228595614433289\tmcate,acc:0.8158735632896423\tlcate,acc:0.8866385817527771\n",
        "Saving checkpoint for epoch 18 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-6\n",
        "Time taken for 1 epoch: 326.76388335227966 secs\n",
        "\n",
        "Epoch 19 Batch 100 Loss 2.6016\n",
        "Seen so far: 102400 samples\n",
        "Epoch 19 Batch 200 Loss 2.5959\n",
        "Seen so far: 204800 samples\n",
        "Epoch 19 Batch 300 Loss 2.5860\n",
        "Seen so far: 307200 samples\n",
        "Epoch 19 Batch 400 Loss 2.5807\n",
        "Seen so far: 409600 samples\n",
        "Epoch 19 Batch 500 Loss 2.5789\n",
        "Seen so far: 512000 samples\n",
        "Epoch 19 Batch 600 Loss 2.5800\n",
        "Seen so far: 614400 samples\n",
        "Epoch 19 Batch 700 Loss 2.5782\n",
        "Seen so far: 716800 samples\n",
        "Epoch 19 Batch 800 Loss 2.5790\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.578908681869507, acc dcate,acc:0.686680257320404\tscate,acc:0.7661811113357544\tmcate,acc:0.8554387092590332\tlcate,acc:0.9157086610794067 over epoch 19\n",
        "Validation acc over epoch 19: dcate,acc:0.6471402049064636\tscate,acc:0.7249501943588257\tmcate,acc:0.8169732689857483\tlcate,acc:0.8857994675636292\n",
        "Time taken for 1 epoch: 324.250257730484 secs\n",
        "\n",
        "Epoch 20 Batch 100 Loss 2.5586\n",
        "Seen so far: 102400 samples\n",
        "Epoch 20 Batch 200 Loss 2.5536\n",
        "Seen so far: 204800 samples\n",
        "Epoch 20 Batch 300 Loss 2.5477\n",
        "Seen so far: 307200 samples\n",
        "Epoch 20 Batch 400 Loss 2.5451\n",
        "Seen so far: 409600 samples\n",
        "Epoch 20 Batch 500 Loss 2.5452\n",
        "Seen so far: 512000 samples\n",
        "Epoch 20 Batch 600 Loss 2.5461\n",
        "Seen so far: 614400 samples\n",
        "Epoch 20 Batch 700 Loss 2.5452\n",
        "Seen so far: 716800 samples\n",
        "Epoch 20 Batch 800 Loss 2.5463\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.5459542274475098, acc dcate,acc:0.6887779831886292\tscate,acc:0.7682754993438721\tmcate,acc:0.8569892048835754\tlcate,acc:0.9172168374061584 over epoch 20\n",
        "Validation acc over epoch 20: dcate,acc:0.6497806310653687\tscate,acc:0.726370632648468\tmcate,acc:0.8177894949913025\tlcate,acc:0.886787474155426\n",
        "Time taken for 1 epoch: 325.4898090362549 secs\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN7YWPhMCT5Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXi3OyqbewuE",
        "colab_type": "text"
      },
      "source": [
        "#### 학습로그, BATCH_SIZE=2,048"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Q_XD7Pe14x",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Epoch 1 Batch 100 Loss 20.7126\n",
        "Seen so far: 204800 samples\n",
        "Epoch 1 Batch 200 Loss 19.1006\n",
        "Seen so far: 409600 samples\n",
        "Epoch 1 Batch 300 Loss 17.5073\n",
        "Seen so far: 614400 samples\n",
        "Epoch 1 Batch 400 Loss 16.1323\n",
        "Seen so far: 819200 samples\n",
        "Training loss 15.654592514038086, acc dcate,acc:0.07290183752775192\tscate,acc:0.158364400267601\tmcate,acc:0.29980024695396423\tlcate,acc:0.5377344489097595 over epoch 1\n",
        "Validation acc over epoch 1: dcate,acc:0.21368910372257233\tscate,acc:0.3176470696926117\tmcate,acc:0.5324735641479492\tlcate,acc:0.7498018145561218\n",
        "Time taken for 1 epoch: 359.1522009372711 secs\n",
        "\n",
        "Epoch 2 Batch 100 Loss 9.7618\n",
        "Seen so far: 204800 samples\n",
        "Epoch 2 Batch 200 Loss 9.1928\n",
        "Seen so far: 409600 samples\n",
        "Epoch 2 Batch 300 Loss 8.7245\n",
        "Seen so far: 614400 samples\n",
        "Epoch 2 Batch 400 Loss 8.3452\n",
        "Seen so far: 819200 samples\n",
        "Training loss 8.21285343170166, acc dcate,acc:0.3184172213077545\tscate,acc:0.4169376790523529\tmcate,acc:0.6051706671714783\tlcate,acc:0.7719826698303223 over epoch 2\n",
        "Validation acc over epoch 2: dcate,acc:0.4078182578086853\tscate,acc:0.513801097869873\tmcate,acc:0.6864631175994873\tlcate,acc:0.8109892010688782\n",
        "Time taken for 1 epoch: 338.88829922676086 secs\n",
        "\n",
        "Epoch 3 Batch 100 Loss 6.5688\n",
        "Seen so far: 204800 samples\n",
        "Epoch 3 Batch 200 Loss 6.3846\n",
        "Seen so far: 409600 samples\n",
        "Epoch 3 Batch 300 Loss 6.2236\n",
        "Seen so far: 614400 samples\n",
        "Epoch 3 Batch 400 Loss 6.0866\n",
        "Seen so far: 819200 samples\n",
        "Training loss 6.036114692687988, acc dcate,acc:0.4433082044124603\tscate,acc:0.5432434678077698\tmcate,acc:0.6916353702545166\tlcate,acc:0.8083312511444092 over epoch 3\n",
        "Validation acc over epoch 3: dcate,acc:0.4938131868839264\tscate,acc:0.5952177047729492\tmcate,acc:0.7269847393035889\tlcate,acc:0.8270421624183655\n",
        "Saving checkpoint for epoch 3 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-1\n",
        "Time taken for 1 epoch: 329.042849779129 secs\n",
        "\n",
        "Epoch 4 Batch 100 Loss 5.3765\n",
        "Seen so far: 204800 samples\n",
        "Epoch 4 Batch 200 Loss 5.2882\n",
        "Seen so far: 409600 samples\n",
        "Epoch 4 Batch 300 Loss 5.2074\n",
        "Seen so far: 614400 samples\n",
        "Epoch 4 Batch 400 Loss 5.1386\n",
        "Seen so far: 819200 samples\n",
        "Training loss 5.111425876617432, acc dcate,acc:0.5046759247779846\tscate,acc:0.6007372140884399\tmcate,acc:0.7245070338249207\tlcate,acc:0.8248827457427979 over epoch 4\n",
        "Validation acc over epoch 4: dcate,acc:0.5347713828086853\tscate,acc:0.6312241554260254\tmcate,acc:0.7467802166938782\tlcate,acc:0.8399844765663147\n",
        "Time taken for 1 epoch: 328.50467562675476 secs\n",
        "\n",
        "Epoch 5 Batch 100 Loss 4.7599\n",
        "Seen so far: 204800 samples\n",
        "Epoch 5 Batch 200 Loss 4.7062\n",
        "Seen so far: 409600 samples\n",
        "Epoch 5 Batch 300 Loss 4.6538\n",
        "Seen so far: 614400 samples\n",
        "Epoch 5 Batch 400 Loss 4.6114\n",
        "Seen so far: 819200 samples\n",
        "Training loss 4.593683242797852, acc dcate,acc:0.5402659773826599\tscate,acc:0.6321774125099182\tmcate,acc:0.7447924017906189\tlcate,acc:0.8380663394927979 over epoch 5\n",
        "Validation acc over epoch 5: dcate,acc:0.5618681311607361\tscate,acc:0.6526281237602234\tmcate,acc:0.7593032121658325\tlcate,acc:0.8461540937423706\n",
        "Time taken for 1 epoch: 328.8026864528656 secs\n",
        "\n",
        "Epoch 6 Batch 100 Loss 4.3561\n",
        "Seen so far: 204800 samples\n",
        "Epoch 6 Batch 200 Loss 4.3189\n",
        "Seen so far: 409600 samples\n",
        "Epoch 6 Batch 300 Loss 4.2840\n",
        "Seen so far: 614400 samples\n",
        "Epoch 6 Batch 400 Loss 4.2569\n",
        "Seen so far: 819200 samples\n",
        "Training loss 4.2443742752075195, acc dcate,acc:0.5655531287193298\tscate,acc:0.6538052558898926\tmcate,acc:0.7604385614395142\tlcate,acc:0.8485127091407776 over epoch 6\n",
        "Validation acc over epoch 6: dcate,acc:0.5805060863494873\tscate,acc:0.6682358980178833\tmcate,acc:0.7716050148010254\tlcate,acc:0.8548626899719238\n",
        "Saving checkpoint for epoch 6 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-2\n",
        "Time taken for 1 epoch: 328.5753698348999 secs\n",
        "\n",
        "Epoch 7 Batch 100 Loss 4.0764\n",
        "Seen so far: 204800 samples\n",
        "Epoch 7 Batch 200 Loss 4.0440\n",
        "Seen so far: 409600 samples\n",
        "Epoch 7 Batch 300 Loss 4.0168\n",
        "Seen so far: 614400 samples\n",
        "Epoch 7 Batch 400 Loss 3.9969\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.9883029460906982, acc dcate,acc:0.5843369364738464\tscate,acc:0.6698818206787109\tmcate,acc:0.7726767063140869\tlcate,acc:0.857229471206665 over epoch 7\n",
        "Validation acc over epoch 7: dcate,acc:0.5922161936759949\tscate,acc:0.678630530834198\tmcate,acc:0.7791905999183655\tlcate,acc:0.8594152331352234\n",
        "Time taken for 1 epoch: 328.5116934776306 secs\n",
        "\n",
        "Epoch 8 Batch 100 Loss 3.8580\n",
        "Seen so far: 204800 samples\n",
        "Epoch 8 Batch 200 Loss 3.8330\n",
        "Seen so far: 409600 samples\n",
        "Epoch 8 Batch 300 Loss 3.8117\n",
        "Seen so far: 614400 samples\n",
        "Epoch 8 Batch 400 Loss 3.7988\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.792379856109619, acc dcate,acc:0.5982691049575806\tscate,acc:0.6822735071182251\tmcate,acc:0.7833132147789001\tlcate,acc:0.8647783398628235 over epoch 8\n",
        "Validation acc over epoch 8: dcate,acc:0.6023581027984619\tscate,acc:0.6859001517295837\tmcate,acc:0.7848747968673706\tlcate,acc:0.8628360629081726\n",
        "Time taken for 1 epoch: 329.2802770137787 secs\n",
        "\n",
        "Epoch 9 Batch 100 Loss 3.6920\n",
        "Seen so far: 204800 samples\n",
        "Epoch 9 Batch 200 Loss 3.6729\n",
        "Seen so far: 409600 samples\n",
        "Epoch 9 Batch 300 Loss 3.6564\n",
        "Seen so far: 614400 samples\n",
        "Epoch 9 Batch 400 Loss 3.6465\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.6407313346862793, acc dcate,acc:0.6086587309837341\tscate,acc:0.6918110847473145\tmcate,acc:0.7913737893104553\tlcate,acc:0.8709580302238464 over epoch 9\n",
        "Validation acc over epoch 9: dcate,acc:0.6070599555969238\tscate,acc:0.6897633075714111\tmcate,acc:0.7873793840408325\tlcate,acc:0.862580418586731\n",
        "Saving checkpoint for epoch 9 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-3\n",
        "Time taken for 1 epoch: 328.94570541381836 secs\n",
        "\n",
        "Epoch 10 Batch 100 Loss 3.5643\n",
        "Seen so far: 204800 samples\n",
        "Epoch 10 Batch 200 Loss 3.5365\n",
        "Seen so far: 409600 samples\n",
        "Epoch 10 Batch 300 Loss 3.5111\n",
        "Seen so far: 614400 samples\n",
        "Epoch 10 Batch 400 Loss 3.4958\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.487203359603882, acc dcate,acc:0.6195443868637085\tscate,acc:0.7015722990036011\tmcate,acc:0.7999181151390076\tlcate,acc:0.8767951726913452 over epoch 10\n",
        "Validation acc over epoch 10: dcate,acc:0.6154842376708984\tscate,acc:0.6970645785331726\tmcate,acc:0.7936667203903198\tlcate,acc:0.8693617582321167\n",
        "Time taken for 1 epoch: 328.8429343700409 secs\n",
        "\n",
        "Epoch 11 Batch 100 Loss 3.3983\n",
        "Seen so far: 204800 samples\n",
        "Epoch 11 Batch 200 Loss 3.3699\n",
        "Seen so far: 409600 samples\n",
        "Epoch 11 Batch 300 Loss 3.3499\n",
        "Seen so far: 614400 samples\n",
        "Epoch 11 Batch 400 Loss 3.3368\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.330162286758423, acc dcate,acc:0.630510151386261\tscate,acc:0.7115025520324707\tmcate,acc:0.8090275526046753\tlcate,acc:0.8832206726074219 over epoch 11\n",
        "Validation acc over epoch 11: dcate,acc:0.6214786171913147\tscate,acc:0.7011575102806091\tmcate,acc:0.7979118824005127\tlcate,acc:0.8723489046096802\n",
        "Time taken for 1 epoch: 329.15449500083923 secs\n",
        "\n",
        "Epoch 12 Batch 100 Loss 3.2527\n",
        "Seen so far: 204800 samples\n",
        "Epoch 12 Batch 200 Loss 3.2288\n",
        "Seen so far: 409600 samples\n",
        "Epoch 12 Batch 300 Loss 3.2143\n",
        "Seen so far: 614400 samples\n",
        "Epoch 12 Batch 400 Loss 3.2044\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.1991186141967773, acc dcate,acc:0.6399198174476624\tscate,acc:0.7206208109855652\tmcate,acc:0.8166153430938721\tlcate,acc:0.8892914056777954 over epoch 12\n",
        "Validation acc over epoch 12: dcate,acc:0.6285357475280762\tscate,acc:0.7071346640586853\tmcate,acc:0.8024758696556091\tlcate,acc:0.8766084313392639\n",
        "Saving checkpoint for epoch 12 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-4\n",
        "Time taken for 1 epoch: 329.55933117866516 secs\n",
        "\n",
        "Epoch 13 Batch 100 Loss 3.1382\n",
        "Seen so far: 204800 samples\n",
        "Epoch 13 Batch 200 Loss 3.1132\n",
        "Seen so far: 409600 samples\n",
        "Epoch 13 Batch 300 Loss 3.0982\n",
        "Seen so far: 614400 samples\n",
        "Epoch 13 Batch 400 Loss 3.0927\n",
        "Seen so far: 819200 samples\n",
        "Training loss 3.0879979133605957, acc dcate,acc:0.6485109329223633\tscate,acc:0.7275034785270691\tmcate,acc:0.8226393461227417\tlcate,acc:0.8932310342788696 over epoch 13\n",
        "Validation acc over epoch 13: dcate,acc:0.6319335699081421\tscate,acc:0.7091193795204163\tmcate,acc:0.8053251504898071\tlcate,acc:0.8785788416862488\n",
        "Time taken for 1 epoch: 328.5410506725311 secs\n",
        "\n",
        "Epoch 14 Batch 100 Loss 3.0402\n",
        "Seen so far: 204800 samples\n",
        "Epoch 14 Batch 200 Loss 3.0172\n",
        "Seen so far: 409600 samples\n",
        "Epoch 14 Batch 300 Loss 3.0047\n",
        "Seen so far: 614400 samples\n",
        "Epoch 14 Batch 400 Loss 2.9970\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.9925413131713867, acc dcate,acc:0.6548885703086853\tscate,acc:0.7340391278266907\tmcate,acc:0.8282317519187927\tlcate,acc:0.8970805406570435 over epoch 14\n",
        "Validation acc over epoch 14: dcate,acc:0.633740246295929\tscate,acc:0.7112563252449036\tmcate,acc:0.8067238926887512\tlcate,acc:0.8796558976173401\n",
        "Time taken for 1 epoch: 338.5889711380005 secs\n",
        "\n",
        "Epoch 15 Batch 100 Loss 2.9557\n",
        "Seen so far: 204800 samples\n",
        "Epoch 15 Batch 200 Loss 2.9348\n",
        "Seen so far: 409600 samples\n",
        "Epoch 15 Batch 300 Loss 2.9221\n",
        "Seen so far: 614400 samples\n",
        "Epoch 15 Batch 400 Loss 2.9158\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.913116455078125, acc dcate,acc:0.660336434841156\tscate,acc:0.7390431761741638\tmcate,acc:0.8327786922454834\tlcate,acc:0.9004240036010742 over epoch 15\n",
        "Validation acc over epoch 15: dcate,acc:0.6390941143035889\tscate,acc:0.7150620222091675\tmcate,acc:0.8096105456352234\tlcate,acc:0.8813217878341675\n",
        "Saving checkpoint for epoch 15 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-5\n",
        "Time taken for 1 epoch: 328.47749185562134 secs\n",
        "\n",
        "Epoch 16 Batch 100 Loss 2.8736\n",
        "Seen so far: 204800 samples\n",
        "Epoch 16 Batch 200 Loss 2.8586\n",
        "Seen so far: 409600 samples\n",
        "Epoch 16 Batch 300 Loss 2.8478\n",
        "Seen so far: 614400 samples\n",
        "Epoch 16 Batch 400 Loss 2.8455\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.8411223888397217, acc dcate,acc:0.6663437485694885\tscate,acc:0.7438881397247314\tmcate,acc:0.8367605805397034\tlcate,acc:0.9031823873519897 over epoch 16\n",
        "Validation acc over epoch 16: dcate,acc:0.6401510834693909\tscate,acc:0.7169806957244873\tmcate,acc:0.8107622861862183\tlcate,acc:0.8812614679336548\n",
        "Time taken for 1 epoch: 327.7810001373291 secs\n",
        "\n",
        "Epoch 17 Batch 100 Loss 2.8075\n",
        "Seen so far: 204800 samples\n",
        "Epoch 17 Batch 200 Loss 2.7912\n",
        "Seen so far: 409600 samples\n",
        "Epoch 17 Batch 300 Loss 2.7778\n",
        "Seen so far: 614400 samples\n",
        "Epoch 17 Batch 400 Loss 2.7759\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.773369073867798, acc dcate,acc:0.6710196733474731\tscate,acc:0.7487164735794067\tmcate,acc:0.8406000733375549\tlcate,acc:0.9057572484016418 over epoch 17\n",
        "Validation acc over epoch 17: dcate,acc:0.6425608992576599\tscate,acc:0.7187413573265076\tmcate,acc:0.8133702874183655\tlcate,acc:0.8823328614234924\n",
        "Time taken for 1 epoch: 337.12822246551514 secs\n",
        "\n",
        "Epoch 18 Batch 100 Loss 2.7559\n",
        "Seen so far: 204800 samples\n",
        "Epoch 18 Batch 200 Loss 2.7365\n",
        "Seen so far: 409600 samples\n",
        "Epoch 18 Batch 300 Loss 2.7263\n",
        "Seen so far: 614400 samples\n",
        "Epoch 18 Batch 400 Loss 2.7253\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.7234466075897217, acc dcate,acc:0.6748335957527161\tscate,acc:0.7519075274467468\tmcate,acc:0.8436643481254578\tlcate,acc:0.9075424671173096 over epoch 18\n",
        "Validation acc over epoch 18: dcate,acc:0.6441205143928528\tscate,acc:0.7199362516403198\tmcate,acc:0.8133214712142944\tlcate,acc:0.8830135464668274\n",
        "Saving checkpoint for epoch 18 at gdrive/My Drive/data/checkpoints/train_transformer_classifier/ckpt-6\n",
        "Time taken for 1 epoch: 337.37021827697754 secs\n",
        "\n",
        "Epoch 19 Batch 100 Loss 2.7033\n",
        "Seen so far: 204800 samples\n",
        "Epoch 19 Batch 200 Loss 2.6827\n",
        "Seen so far: 409600 samples\n",
        "Epoch 19 Batch 300 Loss 2.6696\n",
        "Seen so far: 614400 samples\n",
        "Epoch 19 Batch 400 Loss 2.6678\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.665433645248413, acc dcate,acc:0.6792247891426086\tscate,acc:0.7560484409332275\tmcate,acc:0.846586287021637\tlcate,acc:0.9099727272987366 over epoch 19\n",
        "Validation acc over epoch 19: dcate,acc:0.6457576751708984\tscate,acc:0.7217687368392944\tmcate,acc:0.815105140209198\tlcate,acc:0.8831485509872437\n",
        "Time taken for 1 epoch: 336.98484802246094 secs\n",
        "\n",
        "Epoch 20 Batch 100 Loss 2.6458\n",
        "Seen so far: 204800 samples\n",
        "Epoch 20 Batch 200 Loss 2.6321\n",
        "Seen so far: 409600 samples\n",
        "Epoch 20 Batch 300 Loss 2.6223\n",
        "Seen so far: 614400 samples\n",
        "Epoch 20 Batch 400 Loss 2.6201\n",
        "Seen so far: 819200 samples\n",
        "Training loss 2.618417739868164, acc dcate,acc:0.6827172636985779\tscate,acc:0.7591138482093811\tmcate,acc:0.8494080305099487\tlcate,acc:0.9118157625198364 over epoch 20\n",
        "Validation acc over epoch 20: dcate,acc:0.6467313766479492\tscate,acc:0.721567690372467\tmcate,acc:0.815625011920929\tlcate,acc:0.8839499354362488\n",
        "Time taken for 1 epoch: 327.76872539520264 secs\n",
        "\n",
        "```\n",
        "\n"
      ]
    }
  ]
}